#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Video people-tracking + congestion, line-cross counting, occupancy overlay
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
* Congestion   : 0-100 % = (min(occupancy / max_people, 1) Ã— 100)
* People count : forward / backward crossings over a user-defined line
* Occupancy    : current # of tracked persons in frame
* Heat-map     : cumulative person locations, shown as minimap (top-right)
* Colours      : Supervision TRACK palette (same as masks / labels)
* Requirements : supervision â‰¥ 0.21, ultralytics (YOLOE fork) + BoT-SORT
"""
import argparse
import os
import random
import json
from collections import defaultdict
import threading
import queue
import time
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor

import cv2
import numpy as np
from PIL import Image
from tqdm import tqdm
import supervision as sv
from ultralytics import YOLOE
from ultralytics.models.yolo.yoloe.predict_vp import YOLOEVPSegPredictor
import torch

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Tracker â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
from tracker.boostTrack.GBI import GBInterpolation
from tracker.boostTrack.boost_track import BoostTrack

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Global Debug Counter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
_debug_frame_count = 0
_max_debug_frames = 5  # ì²˜ìŒ 5í”„ë ˆì„ë§Œ ë””ë²„ê¹… ì¶œë ¥

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Global Statistics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
class ConfidenceStats:
    """Confidence ë¶„í¬ í†µê³„ë¥¼ ì¶”ì í•˜ëŠ” í´ë˜ìŠ¤"""
    def __init__(self):
        self.high_conf_count = 0
        self.medium_conf_count = 0
        self.low_conf_count = 0
        self.very_low_conf_count = 0
    
    def update(self, high_count, medium_count, low_count, very_low_count):
        self.high_conf_count += high_count
        self.medium_conf_count += medium_count
        self.low_conf_count += low_count
        self.very_low_conf_count += very_low_count
    
    def get_total(self):
        return self.high_conf_count + self.medium_conf_count + self.low_conf_count + self.very_low_conf_count
    
    def print_stats(self, args):
        total = self.get_total()
        vpe_update_count = self.high_conf_count + self.medium_conf_count  # 0.1 ì´ìƒ ëª¨ë‘ VPE ì—…ë°ì´íŠ¸
        print(f"ğŸ“Š Confidence ë¶„í¬ (ì „ì²´):")
        print(f"   - ê³ ì‹ ë¢°ë„ (â‰¥{args.high_conf_thresh}): {self.high_conf_count}ê°œ")
        print(f"   - ì¤‘ì‹ ë¢°ë„ ({args.medium_conf_thresh}~{args.high_conf_thresh}): {self.medium_conf_count}ê°œ")
        print(f"   - VPE ì—…ë°ì´íŠ¸ìš© (â‰¥{args.medium_conf_thresh}): {vpe_update_count}ê°œ")
        print(f"   - ì €ì‹ ë¢°ë„ ({args.very_low_conf_thresh}~{args.medium_conf_thresh}): {self.low_conf_count}ê°œ")
        print(f"   - ì´ˆì €ì‹ ë¢°ë„ (<{args.very_low_conf_thresh}): {self.very_low_conf_count}ê°œ")
        if total > 0:
            print(f"   - ì´ detection ìˆ˜: {total}ê°œ")
            print(f"   - ê³ ì‹ ë¢°ë„ ë¹„ìœ¨: {self.high_conf_count/total*100:.1f}%")
            print(f"   - ì¤‘ì‹ ë¢°ë„ ë¹„ìœ¨: {self.medium_conf_count/total*100:.1f}%")
            print(f"   - VPE ì—…ë°ì´íŠ¸ ë¹„ìœ¨: {vpe_update_count/total*100:.1f}%")
            print(f"   - ì €ì‹ ë¢°ë„ ë¹„ìœ¨: {self.low_conf_count/total*100:.1f}%")
            print(f"   - ì´ˆì €ì‹ ë¢°ë„ ë¹„ìœ¨: {self.very_low_conf_count/total*100:.1f}%")

# ì „ì—­ í†µê³„ ê°ì²´
confidence_stats = ConfidenceStats()
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ROI (Region of Interest) Utilities â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
import json
from shapely.geometry import Polygon, box
from shapely.ops import unary_union
import ast


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ObjectMeta Class â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
class ObjectMeta:
    """
    ê°œì²´ì˜ ëª¨ë“  ë©”íƒ€ë°ì´í„°ë¥¼ ë‹´ëŠ” í´ë˜ìŠ¤
    Detectionë¶€í„° Tracking, Overlayê¹Œì§€ ì¼ê´€ë˜ê²Œ ì‚¬ìš©
    """
    def __init__(self, box=None, mask=None, confidence=None, class_id=None, 
                 class_name=None, track_id=None):
        self.box = box              # [x1, y1, x2, y2] or [cx, cy, w, h]
        self.mask = mask            # segmentation mask array
        self.confidence = confidence # detection confidence score
        self.class_id = class_id    # class index (confidenceì— ë”°ë¼ ì¡°ì •ëœ í´ë˜ìŠ¤)
        self.class_name = class_name # class name string
        self.track_id = track_id    # tracking ID (None initially)
        self.original_class_id = class_id  # ì›ë³¸ í´ë˜ìŠ¤ ID (VPE ì—…ë°ì´íŠ¸ìš©)
    
    def __repr__(self):
        return f"ObjectMeta(class={self.class_name}, track_id={self.track_id}, conf={self.confidence:.2f})"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CLI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
# ANCHOR argparse
def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser()
    # NOTE [args] source & output
    # parser.add_argument("--source", type=str, default="/DL_data_super_hdd/video_label_sandbox/efg_cargil2025_test1.mp4",
    parser.add_argument("--source", type=str, default="/DL_data_super_hdd/video_label_sandbox/efg_cargil2025_test1.mp4",
                        help="Input video path")
    parser.add_argument("--output", type=str, default="output",
                        help="Output directory (optional, defaults to input filename without extension)")
    # Logging
    parser.add_argument("--log-detections", type=bool, default=True,
                        help="Log detection results to label.txt")
    # Model
    parser.add_argument("--checkpoint", type=str,
                        default="pretrain/yoloe-11l-seg.pt",
                        help="YOLOE checkpoint (detection + seg)")
    # NOTE [args] text prompt
    parser.add_argument("--names", nargs="+",
                        # default=["fish", "disco ball", "object"],
                        default=["pig", "disco ball"],
                        help="Custom class names list (index order matters)")
    # NOTE [args] GPU Device
    parser.add_argument("--device", type=str, default="cuda:0",
                        help="Inference device")
    # Inference / tracking
    parser.add_argument("--image-size", type=int, default=640,
                        help="Inference image size")
    parser.add_argument("--conf-thresh", type=float, default=0.001,
                        help="Detection confidence threshold")
    parser.add_argument("--vp-thresh", type=float, default=0.1,
                        help="visual prompt confidence threshold")
    parser.add_argument("--iou-thresh", type=float, default=0.45,
                        help="Detection NMS IoU threshold")
    parser.add_argument("--max-det", type=int, default=1000,
                        help="Maximum number of detections per image")
    parser.add_argument("--track-history", type=int, default=100,
                        help="Frames kept in trajectory history")
    parser.add_argument("--track-det-thresh", type=float, default=0.2,
                        help="Detection confidence threshold for tracking")
    parser.add_argument("--track-iou-thresh", type=float, default=0.5,
                        help="Tracking IoU threshold")
    # Congestion / counting
    parser.add_argument("--max-people", type=int, default=100,
                        help="People count that corresponds to 100 percent congestion")
    parser.add_argument("--line-start", nargs=2, type=float,
                        default=None,
                        help="Counting line start (norm. x y, 0~1)")
    parser.add_argument("--line-end", nargs=2, type=float,
                        default=None,
                        help="Counting line end   (norm. x y, 0~1)")
    # Snapshot
    parser.add_argument("--cross-vp", type=bool, default=True,
                        help="Enable cross visual prompt mode")
    parser.add_argument("--save-interval", type=int, default=65,
                        help="Interval for saving intermediate frames")
    # NOTE [args] Batch processing
    parser.add_argument("--batch-size", type=int, default=64,
                        help="Batch size for inference processing")
    parser.add_argument("--frame-loading-threads", type=int, default=32,
                        help="Number of threads for frame loading")
    parser.add_argument("--vpe-momentum", type=float, default=0.1,
                        help="VPE moving average momentum")
    parser.add_argument("--limit-frame", type=int, default=310,
                        help="Maximum number of frames to process")    
    # Image preprocessing
    parser.add_argument("--sharpen", type=float, default=0.0,
                        help="Image sharpening factor (0.0-1.0)")
    parser.add_argument("--contrast", type=float, default=1.1,
                        help="Image contrast factor (0.5-2.0)")
    parser.add_argument("--brightness", type=float, default=0.0,
                        help="Image brightness adjustment (-50 to 50)")
    parser.add_argument("--denoise", type=float, default=0.1,
                        help="Image denoising strength (0.0-1.0)")
    
    # Reference Image & Label First
    parser.add_argument("--reference_img_path", type=str, default="videos/reference",
                        help="Reference img file path")
    parser.add_argument("--reference_label_path", type=str, default="videos/reference",
                        help="Reference label file path (JSON format)")
    
    # Confidence thresholds
    parser.add_argument("--high-conf-thresh", type=float, default=0.3,
                        help="High confidence threshold (default: 0.3)")
    parser.add_argument("--medium-conf-thresh", type=float, default=0.1,
                        help="Medium confidence threshold (default: 0.1)")
    parser.add_argument("--very-low-conf-thresh", type=float, default=0.01,
                        help="Very low confidence threshold (default: 0.01)")
    
    # NOTE [args] ROI Access Detection
    parser.add_argument("--roi-zones", type=str, 
                        # default=None,
                        default="[[214,392,286,392,290,478,214,478],[864,387,945,383,947,465,869,468],[478,14,735,7,736,225,491,221]]",
                        help="ROI zones as nested list of pixel coordinates")
    parser.add_argument("--roi-names", type=str, 
                        # default=None,
                        default="water_area1,water_area2,feeding_area",
                        help="ROI zone names separated by comma")
    parser.add_argument("--roi-detection-method", choices=['bbox', 'mask', 'hybrid'], 
                        default='bbox', help="ROI detection method: bbox overlap, mask overlap, or hybrid")
    parser.add_argument("--roi-dwell-time", type=float, default=1.0,
                        help="Minimum dwell time in seconds for ROI access detection")
    parser.add_argument("--roi-bbox-threshold", type=float, default=0.1,
                        help="Minimum bbox overlap ratio for ROI detection")
    parser.add_argument("--roi-mask-threshold", type=float, default=0.1,
                        help="Minimum mask overlap ratio for ROI detection")
    parser.add_argument("--roi-exit-grace-time", type=float, default=2.0,
                        help="Grace time in seconds before removing objects that left ROI")
    # NOTE [args] Detection area
    parser.add_argument("--detection-area", type=str, 
                        default="192,0,951,0,997,356,938,719,232,719,153,348",
                        help="Basic detection area as polygon coordinates (e.g., '100,100,500,100,500,400,100,400')")
    # Output resolution
    parser.add_argument("--output-width", type=int, default=1920,
                        help="Output video width (if not set, uses input width)")
    parser.add_argument("--output-height", type=int, default=1080,
                        help="Output video height (if not set, uses input height)")
    return parser.parse_args()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Loader â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def convert_data_to_visuals(data, score_threshold=0.5):
    """
    ë°ì´í„° êµ¬ì¡°ë¥¼ visuals í˜•íƒœë¡œ ë³€í™˜
    data êµ¬ì¡°:
    {
        'annotations': [
            {
                'bbox': [x, y, w, h],  # COCO format (x, y, width, height)
                'category_id': 0,
                'score': 0.95,
                ...
            }
        ],
        'categories': [{'id': 0, 'name': 'class0'}, ...]
    }
    
    visuals êµ¬ì¡°:
    {
        'bboxes': [np.array([[x1, y1, x2, y2], ...])],
        'cls': [np.array([category_id, ...])]
    }
    
    ì‚¬ìš© ì˜ˆì‹œ:
    # ë°ì´í„°ë¥¼ visuals í˜•íƒœë¡œ ë³€í™˜
    visuals = convert_data_to_visuals(data)
    
    # ë˜ëŠ” ì‹ ë¢°ë„ í•„í„°ë§ê³¼ í•¨ê»˜
    visuals = convert_data_to_visuals(data, score_threshold=0.7)
    """
    if not data or 'annotations' not in data:
        return dict(bboxes=[], cls=[])
    
    annotations = data['annotations']
    
    if not annotations:
        return dict(bboxes=[], cls=[])
    
    # bbox ë³€í™˜: COCO format [x, y, w, h] -> [x1, y1, x2, y2]
    bboxes = []
    class_ids = []
    
    for ann in annotations:
        if 'bbox' in ann and 'category_id' in ann:
            # ì‹ ë¢°ë„ í•„í„°ë§ (scoreê°€ ìˆëŠ” ê²½ìš°)
            if 'score' in ann and ann['score'] < score_threshold:
                continue
                
            # COCO format to xyxy format ë³€í™˜
            x, y, w, h = ann['bbox']
            x1, y1, x2, y2 = x, y, x + w, y + h
            
            bboxes.append([x1, y1, x2, y2])
            class_ids.append(ann['category_id'])
    
    if not bboxes:
        return dict(bboxes=[], cls=[])
    
    # visuals í˜•íƒœë¡œ ë³€í™˜
    visuals = dict(
        bboxes=[np.array(bboxes, dtype=np.float32)],
        cls=[np.array(class_ids, dtype=np.int32)]
    )
    
    return visuals


def load_reference_from_json(json_path, class_names):
    """
    JSON íŒŒì¼ì—ì„œ ë ˆí¼ëŸ°ìŠ¤ ë¼ë²¨ì„ ë¡œë“œí•˜ì—¬ visuals í˜•íƒœë¡œ ë³€í™˜
    
    ë°˜í™˜ í˜•íƒœ:
    {
        'bboxes': [np.array([[x1, y1, x2, y2], ...])],
        'cls': [np.array([class_id, ...])]
    }
    """
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # convert_data_to_visuals í•¨ìˆ˜ ì¬ì‚¬ìš©
        visuals = convert_data_to_visuals(data)
        return visuals
    
    except Exception as e:
        print(f"âš ï¸ JSON íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return dict(bboxes=[], cls=[])


def load_reference_pairs_from_folder(folder_path, class_names):
    """
    í´ë”ì—ì„œ jpg/json ìŒì„ ì°¾ì•„ì„œ í´ë˜ìŠ¤ë³„ë¡œ ë ˆí¼ëŸ°ìŠ¤ ë°ì´í„° ë¡œë“œ
    
    Args:
        folder_path: ë ˆí¼ëŸ°ìŠ¤ íŒŒì¼ë“¤ì´ ìˆëŠ” í´ë” ê²½ë¡œ
        class_names: ëª¨ë¸ì—ì„œ ì‚¬ìš©í•  í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
    
    Returns:
        dict: {
            'vp_classes': [...],  # VPë¡œ ì²˜ë¦¬í•  í´ë˜ìŠ¤ë“¤
            'tp_classes': [...],  # TPë¡œ ì²˜ë¦¬í•  í´ë˜ìŠ¤ë“¤
            'vp_data': {...},     # VPìš© ì‹œê°ì  ë°ì´í„°
            'reference_files': {...}  # íŒŒì¼ ì •ë³´
        }
    """
    import glob
    
    if not os.path.exists(folder_path):
        print(f"âš ï¸ ë ˆí¼ëŸ°ìŠ¤ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {folder_path}")
        return {
            'vp_classes': [],
            'tp_classes': class_names,
            'vp_data': dict(bboxes=[], cls=[]),
            'reference_files': {}
        }
    
    # jpg íŒŒì¼ë“¤ ì°¾ê¸°
    jpg_files = glob.glob(os.path.join(folder_path, "*.jpg"))
    
    vp_classes = []      # VPë¡œ ì²˜ë¦¬í•  í´ë˜ìŠ¤ë“¤
    tp_classes = []      # TPë¡œ ì²˜ë¦¬í•  í´ë˜ìŠ¤ë“¤  
    vp_images = []       # VPìš© ì´ë¯¸ì§€ë“¤
    vp_bboxes = []       # VPìš© ë°”ìš´ë”© ë°•ìŠ¤ë“¤
    vp_cls = []          # VPìš© í´ë˜ìŠ¤ IDë“¤
    reference_files = {} # íŒŒì¼ ì •ë³´ ì €ì¥
    
    print(f"ğŸ“ ë ˆí¼ëŸ°ìŠ¤ í´ë” ìŠ¤ìº”: {folder_path}")
    
    for jpg_path in jpg_files:
        # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°í•˜ì—¬ í´ë˜ìŠ¤ëª… ì¶”ì¶œ
        base_name = os.path.splitext(os.path.basename(jpg_path))[0]
        json_path = os.path.join(folder_path, f"{base_name}.json")
        
        # í•´ë‹¹ json íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if os.path.exists(json_path):
            print(f"   ğŸ“„ ë°œê²¬: {base_name} (jpg + json)")
            
            # í´ë˜ìŠ¤ëª…ì´ args.namesì— ìˆëŠ”ì§€ í™•ì¸
            if base_name in class_names:
                # VPë¡œ ì²˜ë¦¬
                class_id = class_names.index(base_name)
                
                # ì´ë¯¸ì§€ ë¡œë“œ
                img = cv2.imread(jpg_path)
                if img is not None:
                    # JSONì—ì„œ ë°”ìš´ë”© ë°•ìŠ¤ ë¡œë“œ
                    visuals = load_reference_from_json(json_path, class_names)
                    
                    if visuals['bboxes'] and len(visuals['bboxes'][0]) > 0:
                        vp_classes.append(base_name)
                        vp_images.append(img)
                        vp_bboxes.append(visuals['bboxes'][0])
                        
                        # í´ë˜ìŠ¤ IDë¥¼ í•´ë‹¹ í´ë˜ìŠ¤ë¡œ ì„¤ì •
                        cls_array = np.full(len(visuals['bboxes'][0]), class_id, dtype=np.int32)
                        vp_cls.append(cls_array)
                        
                        reference_files[base_name] = {
                            'jpg': jpg_path,
                            'json': json_path,
                            'type': 'VP',
                            'class_id': class_id
                        }
                        
                        print(f"     âœ… VP ì²˜ë¦¬: {base_name} (class_id: {class_id})")
                    else:
                        print(f"     âš ï¸ ë¹ˆ ë°”ìš´ë”© ë°•ìŠ¤: {base_name}")
                else:
                    print(f"     âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {jpg_path}")
            else:
                print(f"     âš ï¸ í´ë˜ìŠ¤ëª… ë¯¸ë“±ë¡: {base_name} (TPë¡œ ì²˜ë¦¬ë  ì˜ˆì •)")
                reference_files[base_name] = {
                    'jpg': jpg_path, 
                    'json': json_path,
                    'type': 'TP'
                }
        else:
            print(f"   âš ï¸ JSON íŒŒì¼ ì—†ìŒ: {base_name}")
    
    # TPë¡œ ì²˜ë¦¬í•  í´ë˜ìŠ¤ë“¤ = args.namesì—ì„œ VP í´ë˜ìŠ¤ë“¤ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€
    tp_classes = [name for name in class_names if name not in vp_classes]
    
    # VP ë°ì´í„° êµ¬ì„±
    vp_data = dict(bboxes=[], cls=[])
    if vp_bboxes:
        vp_data = dict(bboxes=vp_bboxes, cls=vp_cls)
    
    print(f"ğŸ“Š ë ˆí¼ëŸ°ìŠ¤ ë°ì´í„° ìš”ì•½:")
    print(f"   - VP í´ë˜ìŠ¤ ({len(vp_classes)}ê°œ): {vp_classes}")
    print(f"   - TP í´ë˜ìŠ¤ ({len(tp_classes)}ê°œ): {tp_classes}")
    
    return {
        'vp_classes': vp_classes,
        'tp_classes': tp_classes, 
        'vp_data': vp_data,
        'vp_images': vp_images,
        'reference_files': reference_files
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Geometry helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def point_side(p, a, b) -> int:
    """
    Returns sign of point p relative to oriented line a->b.
    +1 : left side, -1 : right side, 0 : on line
    Using 2-D cross-product.
    """
    x, y = p
    x1, y1 = a
    x2, y2 = b
    val = (x2 - x1) * (y - y1) - (y2 - y1) * (x - x1)
    return 0 if val == 0 else (1 if val > 0 else -1)


def parse_roi_zones(roi_zones_str):
    """ROI zones ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ polygon ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if not roi_zones_str:
        return []
    
    try:
        # ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ íŒŒì‹±
        zones_data = ast.literal_eval(roi_zones_str)
        
        polygons = []
        for zone_coords in zones_data:
            if len(zone_coords) < 6 or len(zone_coords) % 2 != 0:
                print(f"âš ï¸ ROI zone ì¢Œí‘œê°€ ì˜ëª»ë¨: {zone_coords} (ìµœì†Œ 3ê°œ ì  í•„ìš”)")
                continue
            
            # [x1,y1,x2,y2,x3,y3,...] â†’ [(x1,y1), (x2,y2), (x3,y3), ...]
            points = [(zone_coords[i], zone_coords[i+1]) for i in range(0, len(zone_coords), 2)]
            
            try:
                polygon = Polygon(points)
                if polygon.is_valid:
                    polygons.append(polygon)
                else:
                    print(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ polygon: {points}")
            except Exception as e:
                print(f"âš ï¸ Polygon ìƒì„± ì‹¤íŒ¨: {points}, ì˜¤ë¥˜: {e}")
        
        return polygons
    
    except Exception as e:
        print(f"ğŸ’¥ ROI zones íŒŒì‹± ì˜¤ë¥˜: {e}")
        return []

def parse_roi_names(roi_names_str, num_zones):
    """ROI names ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if not roi_names_str:
        # ì´ë¦„ì´ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ Zone_0, Zone_1, ... ìƒì„±
        return [f"Zone_{i}" for i in range(num_zones)]
    
    names = [name.strip() for name in roi_names_str.split(',')]
    
    # ì´ë¦„ ê°œìˆ˜ê°€ ë¶€ì¡±í•˜ë©´ ìë™ ìƒì„±ìœ¼ë¡œ ì±„ì›€
    while len(names) < num_zones:
        names.append(f"Zone_{len(names)}")
    
    return names[:num_zones]  # ì´ˆê³¼í•˜ëŠ” ì´ë¦„ì€ ì œê±°

def parse_detection_area(detection_area_str):
    """ê¸°ë³¸ ê°ì§€ ì˜ì—­ ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ polygonìœ¼ë¡œ ë³€í™˜"""
    if not detection_area_str:
        return None
    
    try:
        # ë¬¸ìì—´ì„ ìˆ«ì ë¦¬ìŠ¤íŠ¸ë¡œ íŒŒì‹±
        coords = [float(x.strip()) for x in detection_area_str.split(',')]
        
        if len(coords) < 6 or len(coords) % 2 != 0:
            print(f"âš ï¸ ê¸°ë³¸ ê°ì§€ ì˜ì—­ ì¢Œí‘œê°€ ì˜ëª»ë¨: {coords} (ìµœì†Œ 3ê°œ ì  í•„ìš”)")
            return None
        
        # [x1,y1,x2,y2,x3,y3,...] â†’ [(x1,y1), (x2,y2), (x3,y3), ...]
        points = [(coords[i], coords[i+1]) for i in range(0, len(coords), 2)]
        
        try:
            polygon = Polygon(points)
            if polygon.is_valid:
                print(f"âœ… ê¸°ë³¸ ê°ì§€ ì˜ì—­ ì„¤ì • ì™„ë£Œ: {len(points)}ê°œ ì ")
                return polygon
            else:
                print(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ ê¸°ë³¸ ê°ì§€ ì˜ì—­: {points}")
                return None
        except Exception as e:
            print(f"âš ï¸ ê¸°ë³¸ ê°ì§€ ì˜ì—­ Polygon ìƒì„± ì‹¤íŒ¨: {points}, ì˜¤ë¥˜: {e}")
            return None
    
    except Exception as e:
        print(f"ğŸ’¥ ê¸°ë³¸ ê°ì§€ ì˜ì—­ íŒŒì‹± ì˜¤ë¥˜: {e}")
        return None

def calculate_bbox_polygon_overlap(bbox, polygon):
    """bboxì™€ polygonì˜ ê²¹ì¹¨ ë¹„ìœ¨ ê³„ì‚°"""
    try:
        x1, y1, x2, y2 = bbox
        bbox_polygon = box(x1, y1, x2, y2)
        
        if not bbox_polygon.is_valid or not polygon.is_valid:
            return 0.0
        
        intersection = bbox_polygon.intersection(polygon)
        if intersection.is_empty:
            return 0.0
        
        bbox_area = bbox_polygon.area
        if bbox_area == 0:
            return 0.0
        
        overlap_ratio = intersection.area / bbox_area
        return overlap_ratio
    
    except Exception as e:
        print(f"âš ï¸ bbox-polygon ê²¹ì¹¨ ê³„ì‚° ì˜¤ë¥˜: {e}")
        return 0.0

def calculate_mask_polygon_overlap(mask, polygon, image_shape):
    """maskì™€ polygonì˜ ê²¹ì¹¨ ë¹„ìœ¨ ê³„ì‚°"""
    try:
        if mask is None:
            return 0.0
        
        height, width = image_shape[:2]
        
        # maskë¥¼ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
        if mask.shape[:2] != (height, width):
            mask = cv2.resize(mask.astype(np.float32), (width, height), interpolation=cv2.INTER_LINEAR)
        
        # maskë¥¼ booleanìœ¼ë¡œ ë³€í™˜
        mask_bool = mask > 0.5
        
        # polygonì„ maskë¡œ ë³€í™˜
        polygon_coords = np.array(polygon.exterior.coords, dtype=np.int32)
        polygon_mask = np.zeros((height, width), dtype=np.uint8)
        cv2.fillPoly(polygon_mask, [polygon_coords], 1)
        polygon_bool = polygon_mask.astype(bool)
        
        # êµì§‘í•© ê³„ì‚°
        intersection = np.logical_and(mask_bool, polygon_bool)
        intersection_area = np.sum(intersection)
        
        # mask ì „ì²´ ë©´ì 
        mask_area = np.sum(mask_bool)
        if mask_area == 0:
            return 0.0
        
        overlap_ratio = intersection_area / mask_area
        return overlap_ratio
    
    except Exception as e:
        print(f"âš ï¸ mask-polygon ê²¹ì¹¨ ê³„ì‚° ì˜¤ë¥˜: {e}")
        return 0.0

# NOTE Check ROI Access
def check_roi_access(obj, polygon, method, bbox_threshold, mask_threshold, image_shape):
    """ê°ì²´ê°€ ROIì— ì ‘ê·¼í–ˆëŠ”ì§€ í™•ì¸"""
    if method == 'bbox':
        overlap_ratio = calculate_bbox_polygon_overlap(obj.box, polygon)
        return overlap_ratio >= bbox_threshold
    
    elif method == 'mask':
        if obj.mask is None:
            # maskê°€ ì—†ìœ¼ë©´ bboxë¡œ fallback
            overlap_ratio = calculate_bbox_polygon_overlap(obj.box, polygon)
            return overlap_ratio >= bbox_threshold
        else:
            overlap_ratio = calculate_mask_polygon_overlap(obj.mask, polygon, image_shape)
            return overlap_ratio >= mask_threshold
    
    elif method == 'hybrid':
        # 1ë‹¨ê³„: bbox ë¹ ë¥¸ í•„í„°ë§
        bbox_overlap = calculate_bbox_polygon_overlap(obj.box, polygon)
        if bbox_overlap < bbox_threshold:
            return False
        
        # 2ë‹¨ê³„: mask ì •ë°€ ê²€ì‚¬ (bbox ê²¹ì¹¨ì´ ìˆì„ ë•Œë§Œ)
        if obj.mask is not None:
            mask_overlap = calculate_mask_polygon_overlap(obj.mask, polygon, image_shape)
            return mask_overlap >= mask_threshold
        else:
            # maskê°€ ì—†ìœ¼ë©´ bbox ê²°ê³¼ ì‚¬ìš©
            return True
    
    return False

def is_bbox_center_in_polygon(bbox, polygon):
    """bboxì˜ centerê°€ polygon ë‚´ë¶€ì— ìˆëŠ”ì§€ í™•ì¸"""
    try:
        x1, y1, x2, y2 = bbox
        center_x = (x1 + x2) / 2
        center_y = (y1 + y2) / 2
        
        from shapely.geometry import Point
        center_point = Point(center_x, center_y)
        
        return polygon.contains(center_point)
    
    except Exception as e:
        print(f"âš ï¸ Bbox center in polygon ê²€ì‚¬ ì˜¤ë¥˜: {e}")
        return True  # ì˜¤ë¥˜ì‹œ ê¸°ë³¸ì ìœ¼ë¡œ í¬í•¨ëœ ê²ƒìœ¼ë¡œ ì²˜ë¦¬


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ROI Access Manager Class â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
class ROIAccessManager:
    """ROI ì ‘ê·¼ ê°ì§€ ë° í†µê³„ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, roi_polygons, roi_names, detection_method, dwell_time, 
                 bbox_threshold, mask_threshold, fps, exit_grace_time):
        self.roi_polygons = roi_polygons
        self.roi_names = roi_names
        self.detection_method = detection_method
        self.dwell_time = dwell_time
        self.bbox_threshold = bbox_threshold
        self.mask_threshold = mask_threshold
        self.fps = fps
        self.exit_grace_time = exit_grace_time
        
        # ì ‘ê·¼ì— í•„ìš”í•œ í”„ë ˆì„ ìˆ˜ ê³„ì‚°
        self.required_frames = int(dwell_time * fps)
        # í‡´ì¥ ìœ ì˜ˆ í”„ë ˆì„ ìˆ˜ ê³„ì‚°
        self.exit_grace_frames = int(exit_grace_time * fps)
        
        # ê° ROIë³„ í†µê³„
        self.roi_stats = {}
        for i, name in enumerate(roi_names):
            self.roi_stats[name] = {
                'total_access': 0,
                'accessed_labels': set(),
                'track_access_count': {},  # {track_id: access_count}
                'current_tracks': {},  # {track_id: {'enter_frame': frame, 'label': label, 'consecutive_frames': count}}
                'exit_pending_tracks': {}  # {track_id: {'exit_frame': frame, 'grace_frames_left': count}}
            }
        
        print(f"\nğŸ¯ ROI Access Manager ì´ˆê¸°í™”:")
        print(f"   - ROI ê°œìˆ˜: {len(roi_polygons)}")
        print(f"   - ROI ì´ë¦„: {roi_names}")
        print(f"   - ê°ì§€ ë°©ë²•: {detection_method}")
        print(f"   - ì²´ë¥˜ ì‹œê°„: {dwell_time}ì´ˆ ({self.required_frames} í”„ë ˆì„)")
        print(f"   - í‡´ì¥ ìœ ì˜ˆ ì‹œê°„: {exit_grace_time}ì´ˆ ({self.exit_grace_frames} í”„ë ˆì„)")
        print(f"   - bbox ì„ê³„ê°’: {bbox_threshold}")
        print(f"   - mask ì„ê³„ê°’: {mask_threshold}")
    
    def update(self, tracked_objects, frame_idx, image_shape):
        """ë§¤ í”„ë ˆì„ë§ˆë‹¤ ROI ì ‘ê·¼ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        current_frame_tracks = set()
        
        for roi_idx, (polygon, roi_name) in enumerate(zip(self.roi_polygons, self.roi_names)):
            roi_stat = self.roi_stats[roi_name]
            current_roi_tracks = set()
            
            # í˜„ì¬ í”„ë ˆì„ì—ì„œ ì´ ROIì— ìˆëŠ” ê°ì²´ë“¤ í™•ì¸
            for obj in tracked_objects:
                if obj.track_id is None or obj.track_id == -1:
                    continue
                
                # ROI ì ‘ê·¼ í™•ì¸
                is_in_roi = check_roi_access(
                    obj, polygon, self.detection_method,
                    self.bbox_threshold, self.mask_threshold, image_shape
                )
                
                if is_in_roi:
                    current_roi_tracks.add(obj.track_id)
                    current_frame_tracks.add(obj.track_id)
                    
                    if obj.track_id in roi_stat['current_tracks']:
                        # ì´ë¯¸ ROIì— ìˆë˜ ê°ì²´ â†’ ì—°ì† í”„ë ˆì„ ìˆ˜ ì¦ê°€
                        roi_stat['current_tracks'][obj.track_id]['consecutive_frames'] += 1
                        
                        # ì²´ë¥˜ ì‹œê°„ ì¡°ê±´ ë§Œì¡± ì‹œ ì ‘ê·¼ìœ¼ë¡œ ì¹´ìš´íŠ¸
                        if (roi_stat['current_tracks'][obj.track_id]['consecutive_frames'] >= self.required_frames and
                            not roi_stat['current_tracks'][obj.track_id].get('counted', False)):
                            
                            # ì ‘ê·¼ ì¹´ìš´íŠ¸ ì¦ê°€
                            roi_stat['total_access'] += 1
                            roi_stat['accessed_labels'].add(obj.class_name)
                            
                            if obj.track_id not in roi_stat['track_access_count']:
                                roi_stat['track_access_count'][obj.track_id] = 0
                            roi_stat['track_access_count'][obj.track_id] += 1
                            
                            # ì¤‘ë³µ ì¹´ìš´íŠ¸ ë°©ì§€
                            roi_stat['current_tracks'][obj.track_id]['counted'] = True
                            
                            # print(f"ğŸ¯ ROI ì ‘ê·¼ ê°ì§€: {roi_name} - track_id:{obj.track_id} ({obj.class_name})")
                    
                    else:
                        # ìƒˆë¡œ ROIì— ì§„ì…í•œ ê°ì²´
                        roi_stat['current_tracks'][obj.track_id] = {
                            'enter_frame': frame_idx,
                            'label': obj.class_name,
                            'consecutive_frames': 1,
                            'counted': False
                        }
            
            # ROIì—ì„œ ë‚˜ê°„ ê°ì²´ë“¤ ì²˜ë¦¬ (ìœ ì˜ˆ ì‹œê°„ ì ìš©)
            tracks_to_remove = []
            tracks_to_exit_pending = []
            
            # 1. í˜„ì¬ ROIì— ì—†ëŠ” ê°ì²´ë“¤ í™•ì¸
            for track_id in roi_stat['current_tracks']:
                if track_id not in current_roi_tracks:
                    # ğŸ¯ ROIì—ì„œ ë‚˜ê°„ ê°ì²´ â†’ counted=Trueì¸ ê°ì²´ë§Œ í‡´ì¥ ëŒ€ê¸° ìƒíƒœë¡œ ì´ë™
                    if track_id not in roi_stat['exit_pending_tracks']:
                        track_info = roi_stat['current_tracks'][track_id]
                        if track_info.get('counted', False):
                            # ì ‘ê·¼ì´ í™•ì¸ëœ ê°ì²´ë§Œ í‡´ì¥ ëŒ€ê¸°ë¡œ ì´ë™
                            tracks_to_exit_pending.append(track_id)
                        else:
                            # ì ‘ê·¼ ë¯¸í™•ì¸ ê°ì²´ëŠ” ë°”ë¡œ ì œê±°
                            tracks_to_remove.append(track_id)
            
            # 2. í‡´ì¥ ëŒ€ê¸° ìƒíƒœë¡œ ì´ë™
            for track_id in tracks_to_exit_pending:
                roi_stat['exit_pending_tracks'][track_id] = {
                    'exit_frame': frame_idx,
                    'grace_frames_left': self.exit_grace_frames
                }
                # current_tracksì—ì„œëŠ” ì•„ì§ ì œê±°í•˜ì§€ ì•ŠìŒ (ìœ ì˜ˆ ê¸°ê°„ ë™ì•ˆ ìœ ì§€)
            
            # 3. í‡´ì¥ ëŒ€ê¸° ì¤‘ì¸ ê°ì²´ë“¤ì˜ ìœ ì˜ˆ ì‹œê°„ ê°ì†Œ
            exit_pending_to_remove = []
            for track_id in list(roi_stat['exit_pending_tracks'].keys()):
                if track_id in current_roi_tracks:
                    # ë‹¤ì‹œ ROIì— ë“¤ì–´ì˜¨ ê²½ìš° â†’ í‡´ì¥ ëŒ€ê¸° ì·¨ì†Œ
                    del roi_stat['exit_pending_tracks'][track_id]
                    # print(f"ğŸ”„ ROI ì¬ì§„ì…: {roi_name} - track_id:{track_id}")
                else:
                    # ì—¬ì „íˆ ROI ë°–ì— ìˆëŠ” ê²½ìš° â†’ ìœ ì˜ˆ ì‹œê°„ ê°ì†Œ
                    roi_stat['exit_pending_tracks'][track_id]['grace_frames_left'] -= 1
                    
                    if roi_stat['exit_pending_tracks'][track_id]['grace_frames_left'] <= 0:
                        # ìœ ì˜ˆ ì‹œê°„ ë§Œë£Œ â†’ ì™„ì „ ì œê±°
                        exit_pending_to_remove.append(track_id)
                        tracks_to_remove.append(track_id)
            
            # 4. ìœ ì˜ˆ ì‹œê°„ì´ ë§Œë£Œëœ ê°ì²´ë“¤ ì™„ì „ ì œê±°
            for track_id in exit_pending_to_remove:
                del roi_stat['exit_pending_tracks'][track_id]
            
            for track_id in tracks_to_remove:
                if track_id in roi_stat['current_tracks']:
                    del roi_stat['current_tracks'][track_id]
                    # print(f"ğŸšª ROI ì™„ì „ í‡´ì¥: {roi_name} - track_id:{track_id} (ìœ ì˜ˆ ì‹œê°„ ë§Œë£Œ)")
    
    def get_current_roi_tracks(self):
        """í˜„ì¬ ê° ROIì— ìˆëŠ” track_idë“¤ ë°˜í™˜ (í‡´ì¥ ëŒ€ê¸° ì¤‘ì¸ ê°ì²´ í¬í•¨)"""
        current_tracks = {}
        for roi_name, roi_stat in self.roi_stats.items():
            # í˜„ì¬ ROIì— ìˆëŠ” ê°ì²´ë“¤ + í‡´ì¥ ëŒ€ê¸° ì¤‘ì¸ ê°ì²´ë“¤ (ìœ ì˜ˆ ê¸°ê°„ ë™ì•ˆì€ ì—¬ì „íˆ ROIì— ìˆëŠ” ê²ƒìœ¼ë¡œ ê°„ì£¼)
            active_tracks = set(roi_stat['current_tracks'].keys())
            # í‡´ì¥ ëŒ€ê¸° ì¤‘ì¸ ê°ì²´ë“¤ë„ í¬í•¨ (ì‹œê°í™” ëª©ì )
            pending_tracks = set(roi_stat['exit_pending_tracks'].keys())
            all_tracks = active_tracks.union(pending_tracks)
            current_tracks[roi_name] = list(all_tracks)
        return current_tracks
    
    def get_roi_tracks_by_status(self):
        """ğŸ¯ ROI ìƒíƒœë³„ track_idë“¤ì„ ë°˜í™˜ (3ë‹¨ê³„ êµ¬ë¶„)"""
        roi_tracks_status = {}
        
        for roi_name, roi_stat in self.roi_stats.items():
            # ê° ROIë³„ë¡œ ìƒíƒœë³„ track_id ë¶„ë¥˜
            pending_access = []    # ì ‘ê·¼ í™•ì¸ ëŒ€ê¸°
            confirmed_access = []  # ì ‘ê·¼ í™•ì¸
            exit_pending = []      # í‡´ì¥ ëŒ€ê¸°
            
            # 1. current_tracksì—ì„œ ì ‘ê·¼ í™•ì¸ ëŒ€ê¸° vs ì ‘ê·¼ í™•ì¸ êµ¬ë¶„
            for track_id, track_info in roi_stat['current_tracks'].items():
                if track_info.get('counted', False):
                    # ì ‘ê·¼ì´ í™•ì¸ëœ ìƒíƒœ
                    confirmed_access.append(track_id)
                else:
                    # ì•„ì§ ì ‘ê·¼ í™•ì¸ ëŒ€ê¸° ìƒíƒœ
                    pending_access.append(track_id)
            
            # 2. exit_pending_tracksëŠ” ëª¨ë‘ í‡´ì¥ ëŒ€ê¸° ìƒíƒœ
            exit_pending = list(roi_stat['exit_pending_tracks'].keys())
            
            roi_tracks_status[roi_name] = {
                'pending_access': pending_access,      # ë¹¨ê°„ìƒ‰ ì ì„ 
                'confirmed_access': confirmed_access,  # ë¹¨ê°„ìƒ‰ ì‹¤ì„ 
                'exit_pending': exit_pending          # ë¹¨ê°„ìƒ‰ ì ì„ 
            }
        
        return roi_tracks_status
    
    def get_statistics(self):
        """ìµœì¢… í†µê³„ ë°˜í™˜"""
        stats = {}
        for roi_name, roi_stat in self.roi_stats.items():
            stats[roi_name] = {
                'total_access': roi_stat['total_access'],
                'accessed_labels': list(roi_stat['accessed_labels']),
                'track_access_count': dict(roi_stat['track_access_count'])
            }
        return stats
    
    def save_statistics(self, output_path):
        """í†µê³„ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        stats = self.get_statistics()
        
        # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
        metadata = {
            'roi_detection_method': self.detection_method,
            'dwell_time_seconds': self.dwell_time,
            'required_frames': self.required_frames,
            'exit_grace_time_seconds': self.exit_grace_time,
            'exit_grace_frames': self.exit_grace_frames,
            'bbox_threshold': self.bbox_threshold,
            'mask_threshold': self.mask_threshold,
            'roi_names': self.roi_names
        }
        
        result = {
            'metadata': metadata,
            'roi_statistics': stats
        }
        
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            print(f"ğŸ“Š ROI í†µê³„ ì €ì¥ ì™„ë£Œ: {output_path}")
        except Exception as e:
            print(f"ğŸ’¥ ROI í†µê³„ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def print_final_statistics(self):
        """ìµœì¢… í†µê³„ë¥¼ ì½˜ì†”ì— ì¶œë ¥"""
        print(f"\nğŸ¯ ROI ì ‘ê·¼ ê°ì§€ ìµœì¢… í†µê³„:")
        print(f"{'='*50}")
        
        for roi_name, roi_stat in self.roi_stats.items():
            print(f"\nğŸ“ {roi_name}: {roi_stat['total_access']}íšŒ ì ‘ê·¼")
            
            if roi_stat['accessed_labels']:
                print(f"   ì ‘ê·¼í•œ í´ë˜ìŠ¤: {', '.join(sorted(roi_stat['accessed_labels']))}")
            
            if roi_stat['track_access_count']:
                print(f"   Track IDë³„ ì ‘ê·¼ íšŸìˆ˜:")
                for track_id, count in sorted(roi_stat['track_access_count'].items()):
                    print(f"     - Track {track_id}: {count}íšŒ")
            
            if not roi_stat['total_access']:
                print(f"   ì ‘ê·¼ ê¸°ë¡ ì—†ìŒ")
        
        print(f"{'='*50}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ROI Visualization Functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
# NOTE Draw ROI polygons
def draw_roi_polygons(image, roi_polygons, roi_names, roi_stats):
    """ROI polygonë“¤ì„ ì´ë¯¸ì§€ì— ê·¸ë¦¬ê¸° (ë°˜íˆ¬ëª… ìƒ‰ì¹  í¬í•¨)"""
    
    # ë°˜íˆ¬ëª… ë‚´ë¶€ ì±„ìš°ê¸°ë¥¼ ìœ„í•œ ë³µì‚¬ë³¸ ìƒì„±
    overlay = image.copy()
    color = (255, 228, 0)
    
    for i, (polygon, roi_name) in enumerate(zip(roi_polygons, roi_names)):
        try:
            # polygon ì¢Œí‘œ ì¶”ì¶œ
            coords = np.array(polygon.exterior.coords, dtype=np.int32)
            
            # ìƒ‰ìƒ ì„ íƒ
            
            # 1. polygon ë‚´ë¶€ë¥¼ ìƒ‰ìœ¼ë¡œ ì±„ìš°ê¸° (overlayì—ë§Œ - ë‚˜ì¤‘ì— íˆ¬ëª…ë„ ì ìš©)
            cv2.fillPoly(overlay, [coords], color)
        
        except Exception as e:
            print(f"âš ï¸ ROI polygon ê·¸ë¦¬ê¸° ì˜¤ë¥˜: {e}")
    
    # 2. ë°˜íˆ¬ëª… ë‚´ë¶€ ì±„ìš°ê¸° ë¸”ë Œë”© (íˆ¬ëª…ë„ 30%)
    alpha = 0.4
    cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0, image)
    
    # 3. í…Œë‘ë¦¬ ê·¸ë¦¬ê¸° (íˆ¬ëª…ë„ ì—†ì´ ì›ë³¸ imageì— ì§ì ‘)
    for i, (polygon, roi_name) in enumerate(zip(roi_polygons, roi_names)):
        try:
            coords = np.array(polygon.exterior.coords, dtype=np.int32)
            cv2.polylines(image, [coords], isClosed=True, color=color, thickness=8)
            
            # ROI ì´ë¦„ê³¼ ì ‘ê·¼ íšŸìˆ˜ í‘œì‹œ
            if roi_name in roi_stats:
                total_access = roi_stats[roi_name]['total_access']
                
                # polygonì˜ ì¤‘ì‹¬ì  ê³„ì‚°
                centroid = polygon.centroid
                text_x, text_y = int(centroid.x), int(centroid.y)
                
                # í…ìŠ¤íŠ¸ ë°°ê²½
                text = f"{roi_name}: {total_access}"
                font = cv2.FONT_HERSHEY_SIMPLEX
                font_scale = 0.7
                thickness = 2
                (text_w, text_h), baseline = cv2.getTextSize(text, font, font_scale, thickness)
                
                # ë°°ê²½ ì‚¬ê°í˜• (ì›ë³¸ imageì— ì§ì ‘)
                cv2.rectangle(image, (text_x - 5, text_y - text_h - 10), 
                             (text_x + text_w + 5, text_y + 5), color, -1)
                
                # í…ìŠ¤íŠ¸ (ì›ë³¸ imageì— ì§ì ‘)
                cv2.putText(image, text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness)            
        except Exception as e:
            print(f"âš ï¸ ROI polygon í…Œë‘ë¦¬ ê·¸ë¦¬ê¸° ì˜¤ë¥˜: {e}")
    
    return image

def highlight_roi_objects(image, tracked_objects, roi_tracks_status, color_palette):
    """ğŸ¯ ROI ìƒíƒœë³„ë¡œ ê°ì²´ë“¤ì„ í•˜ì´ë¼ì´íŠ¸ (3ë‹¨ê³„ êµ¬ë¶„)"""
    
    # ëª¨ë“  ROIì˜ ìƒíƒœë³„ track_idë“¤ ìˆ˜ì§‘
    confirmed_track_ids = set()  # ì ‘ê·¼ í™•ì¸ (ë¹¨ê°„ìƒ‰ ì‹¤ì„ )
    pending_track_ids = set()    # ì ‘ê·¼ í™•ì¸ ëŒ€ê¸° + í‡´ì¥ ëŒ€ê¸° (ë¹¨ê°„ìƒ‰ ì ì„ )
    
    for roi_name, status_dict in roi_tracks_status.items():
        confirmed_track_ids.update(status_dict['confirmed_access'])
        pending_track_ids.update(status_dict['pending_access'])
        pending_track_ids.update(status_dict['exit_pending'])
    
    # ë¹¨ê°„ìƒ‰ ì •ì˜
    red_color = (255, 0, 0)  # BGR í˜•ì‹
    thickness = 4
    
    for obj in tracked_objects:
        if obj.track_id in confirmed_track_ids:
            # ì ‘ê·¼ í™•ì¸ëœ ê°ì²´ â†’ ë¹¨ê°„ìƒ‰ ì‹¤ì„  í…Œë‘ë¦¬
            x1, y1, x2, y2 = map(int, obj.box)
            cv2.rectangle(image, (x1-2, y1-2), (x2+2, y2+2), red_color, thickness)
            
        elif obj.track_id in pending_track_ids:
            # ì ‘ê·¼ í™•ì¸ ëŒ€ê¸° ë˜ëŠ” í‡´ì¥ ëŒ€ê¸° ê°ì²´ â†’ ë¹¨ê°„ìƒ‰ ì ì„  í…Œë‘ë¦¬
            x1, y1, x2, y2 = map(int, obj.box)
            draw_dashed_rectangle(image, (x1-2, y1-2), (x2+2, y2+2), red_color, thickness)
    
    return image

def draw_dashed_rectangle(image, pt1, pt2, color, thickness, dash_length=10):
    """ğŸ¨ ì ì„ ìœ¼ë¡œ ì‚¬ê°í˜• ê·¸ë¦¬ê¸°"""
    x1, y1 = pt1
    x2, y2 = pt2
    
    # 4ê°œ ë³€ì„ ê°ê° ì ì„ ìœ¼ë¡œ ê·¸ë¦¬ê¸°
    # ìƒë‹¨ ë³€
    draw_dashed_line(image, (x1, y1), (x2, y1), color, thickness, dash_length)
    # í•˜ë‹¨ ë³€  
    draw_dashed_line(image, (x1, y2), (x2, y2), color, thickness, dash_length)
    # ì¢Œì¸¡ ë³€
    draw_dashed_line(image, (x1, y1), (x1, y2), color, thickness, dash_length)
    # ìš°ì¸¡ ë³€
    draw_dashed_line(image, (x2, y1), (x2, y2), color, thickness, dash_length)

def draw_dashed_line(image, pt1, pt2, color, thickness, dash_length=10):
    """ğŸ¨ ì ì„  ê·¸ë¦¬ê¸°"""
    x1, y1 = pt1
    x2, y2 = pt2
    
    # ì„ ë¶„ì˜ ì´ ê¸¸ì´ ê³„ì‚°
    total_length = int(np.sqrt((x2 - x1)**2 + (y2 - y1)**2))
    
    if total_length == 0:
        return
    
    # ë‹¨ìœ„ ë²¡í„° ê³„ì‚°
    dx = (x2 - x1) / total_length
    dy = (y2 - y1) / total_length
    
    # ì ì„  ê·¸ë¦¬ê¸°
    current_length = 0
    while current_length < total_length:
        # í˜„ì¬ ì  ê³„ì‚°
        start_x = int(x1 + dx * current_length)
        start_y = int(y1 + dy * current_length)
        
        # ë‹¤ìŒ ì  ê³„ì‚° (dash_lengthë§Œí¼ ì´ë™)
        end_length = min(current_length + dash_length, total_length)
        end_x = int(x1 + dx * end_length)
        end_y = int(y1 + dy * end_length)
        
        # ì‹¤ì„  êµ¬ê°„ ê·¸ë¦¬ê¸°
        cv2.line(image, (start_x, start_y), (end_x, end_y), color, thickness)
        
        # ë‹¤ìŒ êµ¬ê°„ìœ¼ë¡œ ì´ë™ (ê³µë°± í¬í•¨)
        current_length += dash_length * 2

def draw_detection_area(image, detection_area_polygon, scale_x=1.0, scale_y=1.0):
    """ê¸°ë³¸ ê°ì§€ ì˜ì—­ì„ ì—°ë‘ìƒ‰ í…Œë‘ë¦¬ë¡œ ê·¸ë¦¬ê¸°"""
    if detection_area_polygon is None:
        return image
    
    try:
        # polygon ì¢Œí‘œ ì¶”ì¶œ ë° ìŠ¤ì¼€ì¼ë§
        coords = np.array(detection_area_polygon.exterior.coords, dtype=np.float32)
        scaled_coords = coords * [scale_x, scale_y]
        scaled_coords = scaled_coords.astype(np.int32)
        
        # ì—°ë‘ìƒ‰ (BGR: 0, 255, 0) í…Œë‘ë¦¬ë¡œ ê·¸ë¦¬ê¸°
        lime_green = (83, 255, 76)
        thickness = 8
        
        cv2.polylines(image, [scaled_coords], isClosed=True, color=lime_green, thickness=thickness)
        
        # # ê¸°ë³¸ ê°ì§€ ì˜ì—­ ë¼ë²¨ í‘œì‹œ (polygonì˜ ì¤‘ì‹¬ì ì—)
        # try:
        #     centroid = detection_area_polygon.centroid
        #     text_x = int(centroid.x * scale_x)
        #     text_y = int(centroid.y * scale_y)
            
        #     text = "Detection Area"
        #     font = cv2.FONT_HERSHEY_SIMPLEX
        #     font_scale = 0.8
        #     thickness = 2
        #     (text_w, text_h), baseline = cv2.getTextSize(text, font, font_scale, thickness)
            
        #     # ë°°ê²½ ì‚¬ê°í˜• (ì—°ë‘ìƒ‰)
        #     cv2.rectangle(image, (text_x - 5, text_y - text_h - 10), 
        #                  (text_x + text_w + 5, text_y + 5), lime_green, -1)
            
        #     # í…ìŠ¤íŠ¸ (ê²€ì€ìƒ‰)
        #     cv2.putText(image, text, (text_x, text_y), font, font_scale, (0, 0, 0), thickness)
            
        # except Exception as e:
        #     print(f"âš ï¸ ê¸°ë³¸ ê°ì§€ ì˜ì—­ ë¼ë²¨ ê·¸ë¦¬ê¸° ì˜¤ë¥˜: {e}")
        
    except Exception as e:
        print(f"ğŸ’¥ ê¸°ë³¸ ê°ì§€ ì˜ì—­ ê·¸ë¦¬ê¸° ì˜¤ë¥˜: {e}")
    
    return image


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ObjectMeta Conversion â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def convert_results_to_objects(cpu_result, class_names, detection_area_polygon=None, args=None) -> list[ObjectMeta]:
    """
    CPUë¡œ ë³€í™˜ëœ YOLO ê²°ê³¼ë¥¼ ObjectMeta ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    Confidence ê¸°ì¤€ì— ë”°ë¥¸ í´ë˜ìŠ¤ í• ë‹¹:
    - conf >= 0.1: ì •ìƒì ì¸ í´ë˜ìŠ¤ ë¶€ì—¬
    - 0.01 <= conf < 0.1: 'object' í´ë˜ìŠ¤ë¡œ ë¶€ì—¬
    - conf < 0.01: í•„í„°ë§ (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
    """
    global _debug_frame_count, _max_debug_frames
    
    objects = []
    filtered_count = 0  # í•„í„°ë§ëœ ê°ì²´ ìˆ˜ (í†µê³„ìš©)
    
    if not cpu_result['has_boxes']:
        return objects, filtered_count
    
    boxes = cpu_result['boxes_xyxy']  # ì´ë¯¸ CPU numpy array
    confidences = cpu_result['boxes_conf']  # ì´ë¯¸ CPU numpy array
    class_ids = cpu_result['boxes_cls']  # ì´ë¯¸ CPU numpy array
    
    # ğŸ” Confidence ë¶„í¬ ë””ë²„ê¹… (ì²˜ìŒ ëª‡ í”„ë ˆì„ë§Œ)
    should_debug = _debug_frame_count < _max_debug_frames
    
    if len(confidences) > 0:
        high_conf_count = np.sum(confidences >= args.high_conf_thresh)
        medium_conf_count = np.sum((confidences >= args.medium_conf_thresh) & (confidences < args.high_conf_thresh))
        low_conf_count = np.sum((confidences >= args.very_low_conf_thresh) & (confidences < args.medium_conf_thresh))
        very_low_conf_count = np.sum(confidences < args.very_low_conf_thresh)
        
        # ì „ì—­ í†µê³„ ê°ì²´ì— ì—…ë°ì´íŠ¸
        global confidence_stats
        confidence_stats.update(high_conf_count, medium_conf_count, low_conf_count, very_low_conf_count)
        
        if should_debug:
            print(f"ğŸ“Š í”„ë ˆì„ {_debug_frame_count + 1} - Confidence ë¶„í¬ (ì´ {len(confidences)}ê°œ):")
            print(f"   - conf >= {args.high_conf_thresh}     : {high_conf_count}ê°œ (VPE ì—…ë°ì´íŠ¸ìš©)")
            print(f"   - {args.medium_conf_thresh} <= conf < {args.high_conf_thresh}: {medium_conf_count}ê°œ (ì •ìƒ í´ë˜ìŠ¤)")
            print(f"   - {args.very_low_conf_thresh} <= conf < {args.medium_conf_thresh}: {low_conf_count}ê°œ (â†’ 'object' í´ë˜ìŠ¤)")
            print(f"   - conf < {args.very_low_conf_thresh}     : {very_low_conf_count}ê°œ (í•„í„°ë§ë¨)")
            
            if len(confidences) > 0:
                print(f"   - ìµœê³  confidence: {np.max(confidences):.3f}")
                print(f"   - ìµœì € confidence: {np.min(confidences):.3f}")
                print(f"   - í‰ê·  confidence: {np.mean(confidences):.3f}")
    
    # confidence very_low_conf_thresh ë¯¸ë§Œ í•„í„°ë§
    valid_mask = confidences >= args.very_low_conf_thresh
    boxes = boxes[valid_mask]
    confidences = confidences[valid_mask]
    class_ids = class_ids[valid_mask]
    
    if len(boxes) == 0:
        if should_debug:
            print(f"âš ï¸ {args.very_low_conf_thresh} ì´ìƒì˜ confidenceë¥¼ ê°€ì§„ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return objects
    
    # ë§ˆìŠ¤í¬ ì •ë³´ ì²˜ë¦¬ (ì •êµí•œ ë³€í™˜ ë¡œì§ ì‚¬ìš©)
    masks = None
    if cpu_result['masks_type'] is not None:
        try:
            orig_height, orig_width = cpu_result['orig_shape']
            
            if cpu_result['masks_type'] == 'xy':
                # masks.xy ì‚¬ìš© (ì´ë¯¸ ì›ë³¸ ì¢Œí‘œê³„ë¡œ ë³€í™˜ë¨)
                masks_list = []
                
                for mask_coords in cpu_result['masks_xy']:
                    # polygonì„ ë§ˆìŠ¤í¬ë¡œ ë³€í™˜
                    mask = np.zeros((orig_height, orig_width), dtype=np.uint8)
                    if len(mask_coords) > 0:
                        # polygon ì¢Œí‘œë¥¼ integerë¡œ ë³€í™˜
                        coords = mask_coords.astype(np.int32)
                        # fillPolyë¡œ ë§ˆìŠ¤í¬ ìƒì„±
                        cv2.fillPoly(mask, [coords], 1)
                    masks_list.append(mask)
                
                masks = np.array(masks_list)
                
            elif cpu_result['masks_type'] == 'data':
                # masks.data ì‚¬ìš©
                mask_data = cpu_result['masks_data']  # ì´ë¯¸ CPU numpy array
                
                # YOLOì˜ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì •ë³´ ê³„ì‚°
                input_height, input_width = mask_data.shape[1], mask_data.shape[2]
                
                # aspect ratio ê³„ì‚°
                scale = min(input_width / orig_width, input_height / orig_height)
                scaled_width = int(orig_width * scale)
                scaled_height = int(orig_height * scale)
                
                # íŒ¨ë”© ê³„ì‚°
                pad_x = (input_width - scaled_width) // 2
                pad_y = (input_height - scaled_height) // 2
                
                masks_list = []
                for mask in mask_data:
                    # íŒ¨ë”© ì œê±°
                    if pad_y > 0 and pad_x > 0:
                        mask = mask[pad_y:pad_y + scaled_height, pad_x:pad_x + scaled_width]
                    
                    # ì›ë³¸ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                    resized_mask = cv2.resize(
                        mask.astype(np.float32), 
                        (orig_width, orig_height), 
                        interpolation=cv2.INTER_LINEAR  # ë” ë¶€ë“œëŸ¬ìš´ ë³´ê°„
                    )
                    masks_list.append(resized_mask)
                
                masks = np.array(masks_list)
                
        except Exception as e:
            print(f"âš ï¸ ë§ˆìŠ¤í¬ ë³€í™˜ ì˜¤ë¥˜: {e}")
            masks = None
    
    # ğŸ¯ ì €ì‹ ë¢°ë„ ê°ì²´ëŠ” ì›ë³¸ í´ë˜ìŠ¤ ìœ ì§€ (trackerê°€ confidenceë¡œ êµ¬ë¶„)
    
    # ğŸ” í´ë˜ìŠ¤ í• ë‹¹ ë””ë²„ê¹…ìš© ì¹´ìš´í„°
    high_conf_assigned = 0
    medium_conf_assigned = 0
    low_conf_assigned = 0
    
    for i in range(len(boxes)):
        conf = confidences[i]
        original_class_id = class_ids[i]
        
        # ğŸ¯ í´ë˜ìŠ¤ëŠ” í•­ìƒ ì›ë³¸ í´ë˜ìŠ¤ ìœ ì§€ (trackerê°€ confidenceë¡œ êµ¬ë¶„)
        final_class_id = original_class_id
        final_class_name = class_names[original_class_id] if original_class_id < len(class_names) else "unknown"
        
        # Confidence í†µê³„ë§Œ ì—…ë°ì´íŠ¸
        if conf >= args.high_conf_thresh:
            high_conf_assigned += 1
        elif conf >= args.medium_conf_thresh:
            medium_conf_assigned += 1
        else:  # args.very_low_conf_thresh <= conf < args.medium_conf_thresh
            low_conf_assigned += 1
            if should_debug:
                print(f"ğŸ¯ ì €ì‹ ë¢°ë„ ê°ì²´ ë°œê²¬! conf={conf:.3f}, í´ë˜ìŠ¤={final_class_name} (ì›ë³¸ í´ë˜ìŠ¤ ìœ ì§€, trackerê°€ confidenceë¡œ êµ¬ë¶„)")
        
        obj = ObjectMeta(
            box=boxes[i],
            mask=masks[i] if masks is not None else None,
            confidence=conf,
            class_id=final_class_id,
            class_name=final_class_name,
            track_id=None  # íŠ¸ë˜ì»¤ì—ì„œ ë¶€ì—¬ë°›ì„ ì˜ˆì •
        )
        # ì›ë³¸ í´ë˜ìŠ¤ ì •ë³´ë„ ì €ì¥ (VPE ì—…ë°ì´íŠ¸ìš©)
        obj.original_class_id = original_class_id
        objects.append(obj)
    
            # ìµœì¢… í• ë‹¹ ê²°ê³¼ ì¶œë ¥ (ë””ë²„ê¹… í”„ë ˆì„ì—ì„œë§Œ)
        if should_debug and len(objects) > 0:
            print(f"âœ… í´ë˜ìŠ¤ í• ë‹¹ ì™„ë£Œ (ì›ë³¸ í´ë˜ìŠ¤ ìœ ì§€):")
            print(f"   - ê³ ì‹ ë¢°ë„ (â‰¥{args.high_conf_thresh}): {high_conf_assigned}ê°œ")
            print(f"   - ì¤‘ì‹ ë¢°ë„ ({args.medium_conf_thresh}~{args.high_conf_thresh}): {medium_conf_assigned}ê°œ") 
            print(f"   - ì €ì‹ ë¢°ë„ ({args.very_low_conf_thresh}~{args.medium_conf_thresh}): {low_conf_assigned}ê°œ (ì›ë³¸ í´ë˜ìŠ¤ ìœ ì§€)")
            print(f"   - ì´ í• ë‹¹ëœ ê°ì²´: {len(objects)}ê°œ")
            print("-" * 50)
    
    # ë””ë²„ê·¸ ì¹´ìš´í„° ì¦ê°€
    _debug_frame_count += 1

    # ğŸ¯ ê¸°ë³¸ ê°ì§€ ì˜ì—­ í•„í„°ë§ëœ objectsë¥¼ ì •ë¦¬í•´ì„œ ë°˜í™˜
    filtered_objects = []
    for obj in objects:
        if detection_area_polygon is None or is_bbox_center_in_polygon(obj.box, detection_area_polygon):
            filtered_objects.append(obj)  # ì¡°ê±´ ë§Œì¡±ì‹œì—ë§Œ ì¶”ê°€
        else:
            filtered_count += 1  # í•„í„°ë§ëœ ê°ì²´ ìˆ˜ ì¦ê°€
    
    return filtered_objects, filtered_count


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Direct Overlay Functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def draw_box(image, box, track_id, class_id, color_palette):
    """ë°•ìŠ¤ ê·¸ë¦¬ê¸°"""
    x1, y1, x2, y2 = map(int, box)
    # ìŒìˆ˜ track_idë¥¼ ì–‘ìˆ˜ë¡œ ë³€í™˜
    safe_track_id = abs(track_id) if track_id < 0 else track_id
    color = color_palette.by_idx(safe_track_id).as_bgr()
    cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
    return image

def draw_mask(image, mask, track_id, class_id, color_palette, opacity=0.4):
    """Supervision ë°©ì‹ì˜ ë§ˆìŠ¤í¬ ê·¸ë¦¬ê¸° (ì •êµí•œ í¬ê¸° ë³€í™˜ ì ìš©)"""
    if mask is None:
        return image
    
    # ìŒìˆ˜ track_idë¥¼ ì–‘ìˆ˜ë¡œ ë³€í™˜
    safe_track_id = abs(track_id) if track_id < 0 else track_id
    color = color_palette.by_idx(safe_track_id).as_bgr()
    
    # ë§ˆìŠ¤í¬ í¬ê¸° ê²€ì¦ ë° ìƒì„¸ ë””ë²„ê¹…
    if mask.shape[:2] != image.shape[:2]:
        print(f"ğŸ” ë§ˆìŠ¤í¬ í¬ê¸° ë””ë²„ê¹…:")
        print(f"   Image: {image.shape[:2]} (H, W)")
        print(f"   Mask:  {mask.shape[:2]} (H, W)")
        print(f"   Track: {track_id}, Class: {class_id}")
        
        # ì •í™•í•œ ë¦¬ì‚¬ì´ì¦ˆ
        mask = cv2.resize(
            mask.astype(np.float32), 
            (image.shape[1], image.shape[0]),  # (width, height) ìˆœì„œ ì£¼ì˜
            interpolation=cv2.INTER_LINEAR
        )
        print(f"   Resized: {mask.shape[:2]}")
    
    # boolean ë§ˆìŠ¤í¬ë¡œ ë³€í™˜ (threshold ì¡°ì •)
    mask = mask > 0.3  # thresholdë¥¼ ë‚®ì¶°ì„œ ë” ë§ì€ ì˜ì—­ í¬í•¨
    
    # ë§ˆìŠ¤í¬ ì˜ì—­ì´ ìˆëŠ”ì§€ í™•ì¸
    mask_area = np.sum(mask)
    if mask_area == 0:
        print(f"âš ï¸ ë¹ˆ ë§ˆìŠ¤í¬: track_id={track_id}")
        return image
    
    # Supervision ë°©ì‹: colored_mask ìƒì„± í›„ addWeighted ì‚¬ìš©
    colored_mask = np.array(image, copy=True, dtype=np.uint8)
    colored_mask[mask] = color  # ë§ˆìŠ¤í¬ ì˜ì—­ì—ë§Œ ìƒ‰ìƒ ì ìš©
    
    # addWeightedë¡œ ë¸”ë Œë”© (ì›ë³¸ ì´ë¯¸ì§€ì— ì§ì ‘ ì ìš©)
    cv2.addWeighted(colored_mask, opacity, image, 1 - opacity, 0, dst=image)
    
    return image

def draw_label(image, box, track_id, class_name, confidence, color_palette):
    """ğŸ·ï¸ ë¼ë²¨ ê·¸ë¦¬ê¸° (ì´ë¯¸ì§€ ê²½ê³„ ê³ ë ¤)"""
    x1, y1, x2, y2 = map(int, box)
    # ìŒìˆ˜ track_idë¥¼ ì–‘ìˆ˜ë¡œ ë³€í™˜
    safe_track_id = abs(track_id) if track_id < 0 else track_id
    color = color_palette.by_idx(safe_track_id).as_bgr()
    
    # ë¼ë²¨ í…ìŠ¤íŠ¸
    label = f"{class_name} {track_id} {confidence:.2f}"
    
    # í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚°
    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 0.6
    thickness = 2
    (text_w, text_h), baseline = cv2.getTextSize(label, font, font_scale, thickness)
    
    # ì´ë¯¸ì§€ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
    img_height, img_width = image.shape[:2]
    
    # ë¼ë²¨ ë†’ì´ ê³„ì‚° (íŒ¨ë”© í¬í•¨)
    label_height = text_h + baseline + 10
    
    # ğŸ¯ ë¼ë²¨ ìœ„ì¹˜ ê²°ì •: bbox ìœ„ìª½ì— ê³µê°„ì´ ìˆëŠ”ì§€ í™•ì¸
    if y1 - label_height >= 0:
        # bbox ìœ„ìª½ì— ì¶©ë¶„í•œ ê³µê°„ì´ ìˆìŒ â†’ ìœ„ìª½ì— ê·¸ë¦¬ê¸° (ê¸°ì¡´ ë°©ì‹)
        label_y_top = y1 - text_h - baseline - 10
        label_y_bottom = y1
        text_y = y1 - baseline - 5
    else:
        label_y_top = y1
        label_y_bottom = y1 + text_h + baseline + 10
        text_y = y1 + text_h + 5
    
    # ë¼ë²¨ì´ ì´ë¯¸ì§€ ìš°ì¸¡ì„ ë²—ì–´ë‚˜ëŠ” ê²½ìš° x ì¢Œí‘œ ì¡°ì •
    if x1 + text_w >= img_width:
        x1 = max(0, img_width - text_w)
    
    # ë¼ë²¨ ë°°ê²½ ê·¸ë¦¬ê¸°
    cv2.rectangle(image, (x1, label_y_top), (x1 + text_w, label_y_bottom), color, -1)
    
    # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
    cv2.putText(image, label, (x1, text_y), font, font_scale, (255, 255, 255), thickness)
    
    return image

def draw_low_conf_box(image, box, track_id, class_id, color_palette):
    """ì €ì‹ ë¢°ë„ ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ì ì„  ìŠ¤íƒ€ì¼)"""
    x1, y1, x2, y2 = map(int, box)
    # ìŒìˆ˜ track_idë¥¼ ì–‘ìˆ˜ë¡œ ë³€í™˜
    safe_track_id = abs(track_id) if track_id < 0 else track_id
    color = color_palette.by_idx(safe_track_id).as_bgr()
    
    # ì ì„  íš¨ê³¼ë¥¼ ìœ„í•œ íŒŒë¼ë¯¸í„°
    dash_length = 10
    gap_length = 5
    thickness = 2
    
    # ìƒë‹¨ ì„  (ì ì„ )
    x = x1
    while x < x2:
        end_x = min(x + dash_length, x2)
        cv2.line(image, (x, y1), (end_x, y1), color, thickness)
        x += dash_length + gap_length
    
    # í•˜ë‹¨ ì„  (ì ì„ )
    x = x1
    while x < x2:
        end_x = min(x + dash_length, x2)
        cv2.line(image, (x, y2), (end_x, y2), color, thickness)
        x += dash_length + gap_length
    
    # ì¢Œì¸¡ ì„  (ì ì„ )
    y = y1
    while y < y2:
        end_y = min(y + dash_length, y2)
        cv2.line(image, (x1, y), (x1, end_y), color, thickness)
        y += dash_length + gap_length
    
    # ìš°ì¸¡ ì„  (ì ì„ )
    y = y1
    while y < y2:
        end_y = min(y + dash_length, y2)
        cv2.line(image, (x2, y), (x2, end_y), color, thickness)
        y += dash_length + gap_length
    
    return image

def draw_low_conf_label(image, box, track_id, class_name, confidence, color_palette):
    """ì €ì‹ ë¢°ë„ ë¼ë²¨ ê·¸ë¦¬ê¸° (ë°˜íˆ¬ëª… ë°°ê²½ê³¼ íŠ¹ë³„í•œ í˜•ì‹)"""
    x1, y1, x2, y2 = map(int, box)
    # ìŒìˆ˜ track_idë¥¼ ì–‘ìˆ˜ë¡œ ë³€í™˜
    safe_track_id = abs(track_id) if track_id < 0 else track_id
    color = color_palette.by_idx(safe_track_id).as_bgr()
    
    # ğŸ¯ ë¼ë²¨ í…ìŠ¤íŠ¸ (ì €ì‹ ë¢°ë„ í‘œì‹œ + track ID í¬í•¨)
    if track_id is not None and track_id >= 0:
        # track IDê°€ ë¶€ì—¬ëœ ê²½ìš°: [LOW] í´ë˜ìŠ¤ëª… ID confidence
        label = f"[LOW] {class_name} {track_id} {confidence:.3f}"
    else:
        # track IDê°€ ì—†ëŠ” ê²½ìš°: [LOW] í´ë˜ìŠ¤ëª… confidence
        label = f"[LOW] {class_name} {confidence:.3f}"
    
    
    # í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚°
    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 0.5
    thickness = 1
    (text_w, text_h), baseline = cv2.getTextSize(label, font, font_scale, thickness)
    
    # ë°˜íˆ¬ëª… ë°°ê²½ì„ ìœ„í•œ ì˜¤ë²„ë ˆì´
    overlay = image.copy()
    
    # ë¼ë²¨ ë°°ê²½ ê·¸ë¦¬ê¸° (ë” ì–´ë‘ìš´ ìƒ‰ìƒìœ¼ë¡œ)
    bg_color = tuple(int(c * 0.6) for c in color)  # ì›ë˜ ìƒ‰ìƒì˜ 60%ë¡œ ì–´ë‘¡ê²Œ
    cv2.rectangle(overlay, (x1, y1 - text_h - baseline - 10), 
                  (x1 + text_w + 10, y1), bg_color, -1)
    
    # ë°˜íˆ¬ëª… íš¨ê³¼ ì ìš©
    alpha = 0.7
    cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0, image)
    
    # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸° (ë°ì€ ìƒ‰ìœ¼ë¡œ)
    cv2.putText(image, label, (x1 + 5, y1 - baseline - 5), 
                font, font_scale, (255, 255, 255), thickness)
    
    return image

def draw_objects_overlay(image, objects, color_palette, args=None):
    """ëª¨ë“  ê°œì²´ì˜ overlay ê·¸ë¦¬ê¸° (Supervision ë°©ì‹: í° ê°ì²´ë¶€í„° ì‘ì€ ê°ì²´ ìˆœ)
    ì¶”ì ëœ ëª¨ë“  ê°ì²´ í‘œì‹œ (ì •ìƒ ì‹ ë¢°ë„ + ì €ì‹ ë¢°ë„ ê°ì²´ ëª¨ë‘)
    """
    if not objects:
        return image
    
    # ê°ì²´ íƒ€ì…ë³„ ë¶„ë¦¬ (confidence ê¸°ì¤€ìœ¼ë¡œ ì €ì‹ ë¢°ë„ êµ¬ë¶„)
    normal_objects = []
    low_conf_objects = []
    
    # Default thresholds if args is not provided
    very_low_thresh = args.very_low_conf_thresh if args else 0.01
    medium_thresh = args.medium_conf_thresh if args else 0.1
    
    for obj in objects:
        # ğŸ¯ confidence ê¸°ì¤€ìœ¼ë¡œë§Œ ì €ì‹ ë¢°ë„ êµ¬ë¶„ (í´ë˜ìŠ¤ëŠ” ì›ë³¸ ìœ ì§€)
        if very_low_thresh <= obj.confidence < medium_thresh:
            low_conf_objects.append(obj)
        else:
            normal_objects.append(obj)
    
    # ğŸ” ì‹¤ì‹œê°„ ë””ë²„ê¹… (ê°„ë‹¨í•œ ì¶œë ¥)
    global _debug_frame_count, _max_debug_frames
    if _debug_frame_count <= _max_debug_frames and objects:
        print(f"ğŸ¨ ì‹¤ì œ ì˜¤ë²„ë ˆì´ í‘œì‹œ:")
        print(f"   - ì •ìƒ ê°ì²´: {len(normal_objects)}ê°œ")
        print(f"   - ì €ì‹ ë¢°ë„ object: {len(low_conf_objects)}ê°œ")
        
        if low_conf_objects:
            conf_values = [f"{obj.confidence:.3f}" for obj in low_conf_objects]
            track_ids = [f"{obj.track_id}" for obj in low_conf_objects]
            class_names = [obj.class_name for obj in low_conf_objects]
            print(f"   - ì €ì‹ ë¢°ë„ ê°ì²´ confidence: {', '.join(conf_values)}")
            print(f"   - ì €ì‹ ë¢°ë„ ê°ì²´ í´ë˜ìŠ¤: {', '.join(class_names)}")
            print(f"   - ì €ì‹ ë¢°ë„ ê°ì²´ track_ids: {', '.join(track_ids)}")
    
    all_display_objects = normal_objects + low_conf_objects
    
    if not all_display_objects:
        return image
    
    # ë°•ìŠ¤ area ê³„ì‚°í•˜ì—¬ í° ê²ƒë¶€í„° ì •ë ¬ (Supervisionê³¼ ë™ì¼)
    areas = []
    for obj in all_display_objects:
        x1, y1, x2, y2 = obj.box
        area = (x2 - x1) * (y2 - y1)
        areas.append(area)
    
    # area ê¸°ì¤€ìœ¼ë¡œ í° ê²ƒë¶€í„° ì •ë ¬ (flipìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ)
    sorted_indices = np.flip(np.argsort(areas))
    
    # ë§ˆìŠ¤í¬ë¶€í„° ë¨¼ì € ê·¸ë¦¬ê¸° (supervision ë°©ì‹)
    for idx in sorted_indices:
        obj = all_display_objects[idx]
        display_track_id = obj.track_id if obj.track_id is not None else -999 - idx
        image = draw_mask(image, obj.mask, display_track_id, obj.class_id, color_palette)
    
    # ê·¸ ë‹¤ìŒ ë°•ìŠ¤ì™€ ë¼ë²¨ ê·¸ë¦¬ê¸° (ì›ë˜ ìˆœì„œëŒ€ë¡œ)
    for obj in all_display_objects:
        display_track_id = obj.track_id if obj.track_id is not None else -999
        
        # ğŸ¯ confidence ê¸°ì¤€ìœ¼ë¡œ ì €ì‹ ë¢°ë„ ê°ì²´ íŠ¹ë³„ ìŠ¤íƒ€ì¼ ì ìš©
        if very_low_thresh <= obj.confidence < medium_thresh:
            # ì €ì‹ ë¢°ë„ ê°ì²´: ì ì„  ë°•ìŠ¤ì™€ íŠ¹ë³„ ë¼ë²¨ (ì›ë³¸ í´ë˜ìŠ¤ ìœ ì§€)
            image = draw_low_conf_box(image, obj.box, display_track_id, obj.class_id, color_palette)
            image = draw_low_conf_label(image, obj.box, display_track_id, obj.class_name, 
                                      obj.confidence, color_palette)
        else:
            # ì •ìƒ ê°ì²´: ì¼ë°˜ ìŠ¤íƒ€ì¼
            image = draw_box(image, obj.box, display_track_id, obj.class_id, color_palette)
            image = draw_label(image, obj.box, display_track_id, obj.class_name, 
                              obj.confidence, color_palette)
    
    return image


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Inference Thread Class â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
class InferenceThread(threading.Thread):
    """
    ğŸ§  GPU ì¶”ë¡  ë° VPE ì—…ë°ì´íŠ¸ë¥¼ ì „ë‹´í•˜ëŠ” ìŠ¤ë ˆë“œ
    Frame Loading Thread â†’ Inference Thread â†’ Main Thread íŒŒì´í”„ë¼ì¸ì˜ ì¤‘ê°„ ë‹¨ê³„
    """
    
    def __init__(self, frame_queue, result_queue, model_vp, args, detection_area_polygon=None):
        super().__init__(daemon=True)
        self.frame_queue = frame_queue
        self.result_queue = result_queue
        self.model_vp = model_vp
        self.args = args
        self.detection_area_polygon = detection_area_polygon  # ê²°ê³¼ íŒ¨í‚¤ì§•ì—ì„œ ì‚¬ìš©
        self.stop_event = threading.Event()
        self.prev_vpe = None  # VPE ìƒíƒœ ê´€ë¦¬
        self.vpe_update_epoch = 0  # VPE ì—…ë°ì´íŠ¸ íšŸìˆ˜ë¥¼ epochìœ¼ë¡œ ì‚¬ìš©
        self.stats = {
            'total_batches_processed': 0,
            'total_frames_processed': 0,
            'vpe_updates': 0,
            'failed_batches': 0,
            'filtered_objects': 0  # í•„í„°ë§ëœ ê°ì²´ ìˆ˜ í†µê³„ ì¶”ê°€
        }
        
        print(f"\nğŸ§  Inference Thread ì´ˆê¸°í™”:")
        print(f"   - GPU ë””ë°”ì´ìŠ¤: {args.device}")
        print(f"   - Cross-VP ëª¨ë“œ: {'í™œì„±í™”' if args.cross_vp else 'ë¹„í™œì„±í™”'}")
        print(f"   - Inference Confidence Threshold: {args.conf_thresh}")
        print(f"   - VP Confidence Threshold: {args.vp_thresh}")
        print(f"   - Inference IoU Threshold: {args.iou_thresh}")
        print(f"   - VPE ëª¨ë©˜í…€: {args.vpe_momentum}")
        print(f"\nğŸ“Š Confidence ê¸°ì¤€:")
        print(f"   - conf >= {args.medium_conf_thresh}  : ì •ìƒ í´ë˜ìŠ¤ + ë¡œê¹… (â‰¥0.1)")
        print(f"   - {args.very_low_conf_thresh}~{args.medium_conf_thresh}     : ì €ì‹ ë¢°ë„ (ì›ë³¸ í´ë˜ìŠ¤ ìœ ì§€, trackerê°€ confidenceë¡œ êµ¬ë¶„)")
        print(f"   - conf >= {args.very_low_conf_thresh}  : ëª¨ë‘ VPE ì—…ë°ì´íŠ¸ ì‚¬ìš© (â‰¥0.01)")
        print(f"   - conf < {args.very_low_conf_thresh}  : í•„í„°ë§ (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)")
        print(f"   - ê¸°ë³¸ ê°ì§€ ì˜ì—­: {'ì„¤ì •ë¨' if detection_area_polygon else 'ë¯¸ì„¤ì •'}")
    
    def stop(self):
        """ìŠ¤ë ˆë“œ ì¢…ë£Œ ìš”ì²­"""
        self.stop_event.set()
        print("ğŸ›‘ Inference Thread ì¢…ë£Œ ìš”ì²­ë¨")
    
    # ANCHOR Batch Inference    
    def run(self):
        """ë©”ì¸ GPU ì¶”ë¡  ë£¨í”„"""
        print("\nğŸš€ Inference Thread ì‹œì‘!")
        
        try:
            batch_idx = 0
            while not self.stop_event.is_set():
                try:
                    # Frame Queueì—ì„œ ë°°ì¹˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (íƒ€ì„ì•„ì›ƒ 3ì´ˆ)
                    batch_data = self.frame_queue.get(timeout=3.0)
                    
                    # ì¢…ë£Œ ì‹ í˜¸ í™•ì¸
                    if batch_data is None:
                        print("ğŸ Inference Thread: Frame Loading ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹ ")
                        # Main Threadì—ë„ ì¢…ë£Œ ì‹ í˜¸ ì „ë‹¬
                        self.result_queue.put(None)
                        break
                    
                    # ë°°ì¹˜ ë°ì´í„° ì–¸íŒ¨í‚¹
                    batch_frames = batch_data['batch_frames']
                    batch_indices = batch_data['batch_indices']
                    # batch_original_frames = batch_data['batch_original_frames']
                    loaded_count = batch_data['loaded_count']
                    
                    if not batch_frames:
                        print("âš ï¸ Inference Thread: ë¹ˆ batch ìˆ˜ì‹ , ê±´ë„ˆë›°ê¸°")
                        continue
                    
                    # print(f"ğŸ§  Batch {batch_idx + 1} GPU ì¶”ë¡  ì‹œì‘: {loaded_count} í”„ë ˆì„")
                    
                    # â”€â”€â”€â”€â”€â”€â”€â”€ GPU INFERENCE â”€â”€â”€â”€â”€â”€â”€â”€ #
                    batch_results = self._inference_batch(batch_frames)
                    
                    if batch_results is None:
                        print(f"âŒ Batch {batch_idx + 1} ì¶”ë¡  ì‹¤íŒ¨")
                        self.stats['failed_batches'] += 1
                        continue
                    
                    # â”€â”€â”€â”€â”€â”€â”€â”€ VPE UPDATE â”€â”€â”€â”€â”€â”€â”€â”€ #
                    vpe_updated = False
                    if self.args.cross_vp:
                        vpe_updated = self._update_vpe(batch_results)
                    
                    # ğŸ¯ ê²°ê³¼ íŒ¨í‚¤ì§•: ì—¬ê¸°ì„œ cpu_result â†’ ObjectMeta ë³€í™˜! (ë”± í•œ ë²ˆë§Œ!)
                    batch_detected_objects = []  # ObjectMeta ë¦¬ìŠ¤íŠ¸ë“¤
                    batch_original_frames = []   # ì›ë³¸ í”„ë ˆì„ë“¤
                    
                    for cpu_result in batch_results:
                        # ğŸ¯ cpu_result â†’ ObjectMeta ë³€í™˜ + ê¸°ë³¸ ê°ì§€ ì˜ì—­ í•„í„°ë§
                        detected_objects, filtered_count = convert_results_to_objects(
                            cpu_result, self.args.names, self.detection_area_polygon, self.args
                        )
                        
                        # í•„í„°ë§ í†µê³„ ì—…ë°ì´íŠ¸
                        self.stats['filtered_objects'] += filtered_count
                        
                        batch_detected_objects.append(detected_objects)
                        batch_original_frames.append(cpu_result['orig_img'])
                    
                    result_data = {
                        'batch_detected_objects': batch_detected_objects,  # ObjectMeta ë¦¬ìŠ¤íŠ¸ë“¤
                        'batch_indices': batch_indices,
                        'batch_original_frames': batch_original_frames,
                        'loaded_count': loaded_count,
                        'batch_idx': batch_idx,
                        'vpe_updated': vpe_updated,
                        'prev_vpe_status': self.prev_vpe is not None
                    }
                    
                    # Result Queueì— ì „ë‹¬
                    self.result_queue.put(result_data)
                    
                    # í†µê³„ ì—…ë°ì´íŠ¸
                    self.stats['total_batches_processed'] += 1
                    self.stats['total_frames_processed'] += loaded_count
                    if vpe_updated:
                        self.stats['vpe_updates'] += 1
                    
                    # print(f"âœ… Batch {batch_idx + 1} GPU ì²˜ë¦¬ ì™„ë£Œ: {loaded_count} í”„ë ˆì„ â†’ Result Queue")
                    batch_idx += 1
                    
                except queue.Empty:
                    # Frame Queueê°€ ë¹„ì–´ìˆìœ¼ë©´ ì ì‹œ ëŒ€ê¸°
                    continue
                    
                except Exception as e:
                    print(f"ğŸ’¥ Inference Thread ì˜¤ë¥˜: {e}")
                    import traceback
                    traceback.print_exc()
                    self.stats['failed_batches'] += 1
                    
        except Exception as e:
            print(f"ğŸ’¥ Inference Thread ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
        finally:
            # ğŸš€ GPU ë©”ëª¨ë¦¬ ì™„ì „ ì •ë¦¬
            self.model_vp.predictor = None
            if hasattr(self, 'prev_vpe') and self.prev_vpe is not None:
                del self.prev_vpe
                self.prev_vpe = None
            
            import torch
            torch.cuda.empty_cache()
            
            # ì¢…ë£Œ ì‹ í˜¸ë¥¼ Result Queueì— ë°˜ë“œì‹œ ì „ë‹¬ (Queueê°€ ë¹Œ ë•Œê¹Œì§€ ëŒ€ê¸°)
            print("ğŸ“¤ Inference Thread ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡ ì¤€ë¹„ ì¤‘...")
            queue_full_warning_shown = False
            while True:
                try:
                    self.result_queue.put(None, timeout=1.0)
                    print("ğŸ Inference Thread ì¢…ë£Œ ì‹ í˜¸ Result Queueì— ì „ë‹¬ ì™„ë£Œ!")
                    break
                except queue.Full:
                    if not queue_full_warning_shown:
                        print("â³ Result Queue ê°€ë“í•¨, ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡ì„ ìœ„í•´ ëŒ€ê¸° ì¤‘...")
                        queue_full_warning_shown = True
                    time.sleep(0.1)
            
            print(f"ğŸ“ˆ Inference Thread ìµœì¢… í†µê³„:")
            print(f"   - ì²˜ë¦¬ëœ ë°°ì¹˜ ìˆ˜: {self.stats['total_batches_processed']}")
            print(f"   - ì²˜ë¦¬ëœ í”„ë ˆì„ ìˆ˜: {self.stats['total_frames_processed']}")
            print(f"   - VPE ì—…ë°ì´íŠ¸ íšŸìˆ˜: {self.stats['vpe_updates']}")
            print(f"   - VPE ì—…ë°ì´íŠ¸ epoch: {self.vpe_update_epoch}")
            print(f"   - ì‹¤íŒ¨í•œ ë°°ì¹˜ ìˆ˜: {self.stats['failed_batches']}")
            print(f"   - ê¸°ë³¸ ê°ì§€ ì˜ì—­ì—ì„œ í•„í„°ë§ëœ ê°ì²´ ìˆ˜: {self.stats['filtered_objects']}")
            print("ğŸš€ GPU ë©”ëª¨ë¦¬ ì™„ì „ ì •ë¦¬ ì™„ë£Œ!")
    
    def _inference_batch(self, batch_frames):
        """ë°°ì¹˜ ì¶”ë¡  ì‹¤í–‰ ë° GPU â†’ CPU ë³€í™˜"""
        try:
            batch_size = len(batch_frames)
            
            if self.prev_vpe is not None and self.args.cross_vp:
                # VPE ëª¨ë“œë¡œ ì¶”ë¡ 
                self.model_vp.set_classes(self.args.names, self.prev_vpe)
                self.model_vp.predictor = None
                
                results = self.model_vp.predict(
                    source=batch_frames,
                    imgsz=self.args.image_size,
                    conf=self.args.very_low_conf_thresh,  # very_low_conf_thresh ì´ìƒì˜ ëª¨ë“  ê°ì²´ í¬í•¨
                    iou=self.args.iou_thresh,
                    verbose=False
                )
            else:
                # ê¸°ë³¸ ëª¨ë“œë¡œ ì¶”ë¡ 
                results = self.model_vp.predict(
                    source=batch_frames,
                    imgsz=self.args.image_size,
                    conf=self.args.very_low_conf_thresh,  # very_low_conf_thresh ì´ìƒì˜ ëª¨ë“  ê°ì²´ í¬í•¨
                    iou=self.args.iou_thresh,
                    verbose=False
                )
            
            # ğŸ”¥ GPU â†’ CPU ë³€í™˜ì„ ì—¬ê¸°ì„œ ìˆ˜í–‰í•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í™•ë³´!
            cpu_results = []
            
            for result in results:
                cpu_result = {
                    'boxes_xyxy': result.boxes.xyxy.cpu().numpy() if len(result.boxes) > 0 else np.empty((0, 4)),
                    'boxes_conf': result.boxes.conf.cpu().numpy() if len(result.boxes) > 0 else np.empty(0),
                    'boxes_cls': result.boxes.cls.cpu().numpy().astype(int) if len(result.boxes) > 0 else np.empty(0, dtype=int),
                    'orig_img': result.orig_img,
                    'orig_shape': result.orig_shape,
                    'has_boxes': len(result.boxes) > 0
                }
                
                # ë§ˆìŠ¤í¬ ì •ë³´ ì²˜ë¦¬ (ìˆì„ ê²½ìš°)
                if hasattr(result, 'masks') and result.masks is not None:
                    try:
                        # masks.xy ì‚¬ìš© (ì´ë¯¸ ì›ë³¸ ì¢Œí‘œê³„ë¡œ ë³€í™˜ë¨)
                        if hasattr(result.masks, 'xy') and result.masks.xy is not None:
                            masks_xy_list = []
                            for mask_coords in result.masks.xy:
                                # GPU tensorì¸ì§€ numpy arrayì¸ì§€ í™•ì¸ í›„ ë³€í™˜
                                if hasattr(mask_coords, 'cpu'):
                                    masks_xy_list.append(mask_coords.cpu().numpy())
                                else:
                                    masks_xy_list.append(mask_coords)  # ì´ë¯¸ numpy array
                            cpu_result['masks_xy'] = masks_xy_list
                            cpu_result['masks_type'] = 'xy'
                        # xyê°€ ì—†ìœ¼ë©´ data ì‚¬ìš©
                        elif hasattr(result.masks, 'data'):
                            # GPU tensorì¸ì§€ numpy arrayì¸ì§€ í™•ì¸ í›„ ë³€í™˜
                            if hasattr(result.masks.data, 'cpu'):
                                cpu_result['masks_data'] = result.masks.data.cpu().numpy()
                            else:
                                cpu_result['masks_data'] = result.masks.data  # ì´ë¯¸ numpy array
                            cpu_result['masks_type'] = 'data'
                        else:
                            cpu_result['masks_type'] = None
                    except Exception as e:
                        print(f"âš ï¸ ë§ˆìŠ¤í¬ CPU ë³€í™˜ ì˜¤ë¥˜: {e}")
                        cpu_result['masks_type'] = None
                else:
                    cpu_result['masks_type'] = None
                
                cpu_results.append(cpu_result)
            
            # ğŸš€ GPU ë©”ëª¨ë¦¬ ì¦‰ì‹œ ì •ë¦¬
            del results
            import torch
            torch.cuda.empty_cache()
            
            return cpu_results
            
        except Exception as e:
            print(f"ğŸ’¥ ë°°ì¹˜ ì¶”ë¡  ì˜¤ë¥˜: {e}")
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            import torch
            torch.cuda.empty_cache()
            return None
    
    def _update_vpe(self, batch_results):
        """VPE ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ë¡œì§ í™œìš©)"""
        try:
            current_vpe = self._update_batch_vpe(batch_results)
            
            if current_vpe is not None:
                if self.prev_vpe is None:
                    # ì²« ë²ˆì§¸ VPE
                    self.prev_vpe = current_vpe
                    self.vpe_update_epoch = 1
                    print(f"ğŸ¯ ì²« ë²ˆì§¸ VPE ì„¤ì • ì™„ë£Œ (epoch: {self.vpe_update_epoch})")
                else:
                    # VPE ì—…ë°ì´íŠ¸ íšŸìˆ˜ ì¦ê°€
                    self.vpe_update_epoch += 1
                    
                    # ì ì§„ì  í•™ìŠµë¥  ì ìš©: ì´ˆê¸°ì—ëŠ” ë†’ì€ í•™ìŠµë¥ , ì ì§„ì ìœ¼ë¡œ ê°ì†Œ
                    learning_rate = max(0.05, 0.3 * (0.95 ** self.vpe_update_epoch))
                    
                    # Moving Average with dynamic learning rate
                    self.prev_vpe = (1 - learning_rate) * self.prev_vpe + learning_rate * current_vpe
                    
                    print(f"ğŸ”„ VPE ì ì§„ì  ì—…ë°ì´íŠ¸ ì™„ë£Œ (epoch: {self.vpe_update_epoch}, lr: {learning_rate:.4f})")
                return True
            else:
                return False
                
        except Exception as e:
            print(f"ğŸ’¥ VPE ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
            return False
    
    def _update_batch_vpe(self, batch_results):
        """ë°°ì¹˜ ê²°ê³¼ì—ì„œ VPE ìƒì„± (CPU ë°ì´í„° ê¸°ë°˜)
        confidence >= very_low_conf_threshì¸ ëª¨ë“  detectionì„ VPE ì—…ë°ì´íŠ¸ì— ì‚¬ìš© (0.01 ì´ìƒ)
        """
        all_prompts = []  # ëª¨ë“  valid confidenceì˜ VPE ì—…ë°ì´íŠ¸ìš©
        
        # Batch ë‚´ ëª¨ë“  í”„ë ˆì„ì—ì„œ valid confidence detection ìˆ˜ì§‘
        for i, cpu_result in enumerate(batch_results):
            if cpu_result['has_boxes']:
                confidences = cpu_result['boxes_conf']  # ì´ë¯¸ CPU numpy array
                boxes = cpu_result['boxes_xyxy']  # ì´ë¯¸ CPU numpy array
                class_ids = cpu_result['boxes_cls']  # ì´ë¯¸ CPU numpy array
                
                # very_low_conf_thresh ì´ìƒì˜ ëª¨ë“  detection ì‚¬ìš© (0.01 ì´ìƒ)
                valid_conf_mask = confidences >= self.args.very_low_conf_thresh
                if np.any(valid_conf_mask):
                    prompt_data = {
                        "bboxes": boxes[valid_conf_mask],
                        "cls": class_ids[valid_conf_mask],  # ì›ë³¸ í´ë˜ìŠ¤ ì‚¬ìš©
                        "frame": cpu_result['orig_img'],
                        "frame_idx": i,
                        "type": "valid_conf"
                    }
                    all_prompts.append(prompt_data)
                    
        if all_prompts:
            # ëª¨ë“  í”„ë¡¬í”„íŠ¸ë“¤ë¡œ VPE ìƒì„±
            batch_vpe = self._generate_batch_vpe(all_prompts)
            
            # í†µê³„ ì¶œë ¥
            total_count = len(all_prompts)
            if total_count > 0:
                print(f"ğŸ¯ VPE ì—…ë°ì´íŠ¸: ì „ì²´ ìœ íš¨ detection {total_count}ê°œ í”„ë ˆì„ (â‰¥0.01)")
            
            return batch_vpe
        else:
            return None
    
    def _generate_batch_vpe(self, prompts_list):
        """ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸ì—ì„œ VPEë¥¼ ë°°ì¹˜ë¡œ ìƒì„± í›„ í‰ê· í™” (ê¸°ì¡´ í•¨ìˆ˜ ë¡œì§ í™œìš©)"""
        
        # ë°°ì¹˜ìš© ì´ë¯¸ì§€ì™€ í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
        batch_images = []
        batch_prompts = {"bboxes": [], "cls": []}
        
        for i, prompt_data in enumerate(prompts_list):
            # ì´ë¯¸ì§€ ì¤€ë¹„
            frame_rgb = cv2.cvtColor(prompt_data["frame"], cv2.COLOR_BGR2RGB)
            batch_images.append(Image.fromarray(frame_rgb))
            
            # í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
            batch_prompts["bboxes"].append(prompt_data["bboxes"])
            batch_prompts["cls"].append(prompt_data["cls"])
        
        try:
            # ë°°ì¹˜ VPE ìƒì„±
            self.model_vp.predictor = None  # VPE ìƒì„± ì „ ì´ˆê¸°í™”
            self.model_vp.predict(
                source=batch_images,
                prompts=batch_prompts,
                predictor=YOLOEVPSegPredictor,
                return_vpe=True,
                imgsz=self.args.image_size,
                conf=self.args.vp_thresh,
                iou=self.args.iou_thresh,
                verbose=False
            )
            
            # VPE ì¶”ì¶œ
            if hasattr(self.model_vp, 'predictor') and hasattr(self.model_vp.predictor, 'vpe'):
                batch_vpe = self.model_vp.predictor.vpe
                
                # ë°°ì¹˜ ì°¨ì›ì„ í‰ê· í™”í•˜ì—¬ ë‹¨ì¼ VPEë¡œ ë³€í™˜
                if len(batch_vpe.shape) > 2:  # (batch_size, classes, features) í˜•íƒœì¸ ê²½ìš°
                    averaged_vpe = batch_vpe.mean(dim=0, keepdim=True)  # (1, classes, features)
                else:
                    averaged_vpe = batch_vpe
                
                # ğŸš€ ì˜ˆì¸¡ê¸° ì •ë¦¬ ë° GPU ë©”ëª¨ë¦¬ í•´ì œ
                self.model_vp.predictor = None
                del batch_vpe
                import torch
                torch.cuda.empty_cache()
                
                return averaged_vpe
            else:
                self.model_vp.predictor = None
                import torch
                torch.cuda.empty_cache()
                return None
                
        except Exception as e:
            print(f"ğŸ’¥ ë°°ì¹˜ VPE ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            self.model_vp.predictor = None
            import torch
            torch.cuda.empty_cache()
            return None
    

    



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Frame Loading Thread Class â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
class FrameLoadingThread(threading.Thread):
    """
    ğŸš€ Producer-Consumer íŒ¨í„´ìœ¼ë¡œ ê°œì„ ëœ í”„ë ˆì„ ë¡œë”© ìŠ¤ë ˆë“œ
    
    êµ¬ì¡°:
    1. VideoCaptureëŠ” ì´ˆê¸°í™” ì‹œ í•œ ë²ˆë§Œ ìƒì„±
    2. ë‚´ë¶€ ì½ê¸° ìŠ¤ë ˆë“œê°€ ì§€ì†ì ìœ¼ë¡œ í”„ë ˆì„ ì½ê¸°
    3. í”„ë ˆì„ ë²„í¼ì— frame_idì™€ í•¨ê»˜ ì €ì¥
    4. ë°°ì¹˜ êµ¬ì„± ì‹œ ë²„í¼ì—ì„œ êº¼ë‚´ì„œ ì‚¬ìš© (ì¦‰ì‹œ ì‚­ì œ)
    5. ìµœëŒ€ ë²„í¼ í¬ê¸°ë¡œ ë©”ëª¨ë¦¬ ì œì–´
    """
    
    def __init__(self, video_source, total_frames, batch_size, args, batch_queue, 
                 max_queue_size=3, max_buffer_size=200):
        super().__init__(daemon=True)
        self.video_source = video_source
        self.total_frames = total_frames
        self.batch_size = batch_size
        self.args = args
        self.batch_queue = batch_queue
        self.max_queue_size = max_queue_size
        self.max_buffer_size = max_buffer_size  # í”„ë ˆì„ ë²„í¼ ìµœëŒ€ í¬ê¸°
        
        # ìƒíƒœ ê´€ë¦¬
        self.current_frame = 0
        self.stop_event = threading.Event()
        self.queue_full_print = False
        
        # ğŸ¯ í•µì‹¬: í”„ë ˆì„ ë²„í¼ (Producer-Consumer)
        self.frame_buffer = {}  # {frame_id: frame_data}
        self.buffer_lock = threading.Lock()
        self.buffer_not_full = threading.Condition(self.buffer_lock)
        self.frames_available = threading.Condition(self.buffer_lock)
        
        # í†µê³„
        self.stats = {
            'total_batches_loaded': 0,
            'total_frames_loaded': 0,
            'failed_frames': 0,
            'buffer_waits': 0,
            'max_buffer_used': 0
        }
        
        # VideoCapture ì´ˆê¸°í™” (í•œ ë²ˆë§Œ!)
        self.cap = cv2.VideoCapture(self.video_source)
        if not self.cap.isOpened():
            raise RuntimeError(f"VideoCapture ì—´ê¸° ì‹¤íŒ¨: {self.video_source}")
        
        # ë‚´ë¶€ í”„ë ˆì„ ì½ê¸° ìŠ¤ë ˆë“œ ìƒì„±
        self.reader_thread = threading.Thread(target=self._continuous_frame_reader, daemon=True)
        self.reader_started = False
        
        print(f"\nğŸ¬ Frame Loading Thread ì´ˆê¸°í™”:")
        print(f"   - ì´ í”„ë ˆì„: {total_frames}")
        print(f"   - ë°°ì¹˜ í¬ê¸°: {batch_size}")
        print(f"   - Queue ìµœëŒ€ í¬ê¸°: {max_queue_size}")
        print(f"   - í”„ë ˆì„ ë²„í¼ ìµœëŒ€ í¬ê¸°: {max_buffer_size}")
        print(f"   - VideoCapture: ì´ˆê¸°í™” ì™„ë£Œ âœ…")
    
    def stop(self):
        """ìŠ¤ë ˆë“œ ì¢…ë£Œ ìš”ì²­"""
        self.stop_event.set()
        # ëª¨ë“  ëŒ€ê¸° ì¤‘ì¸ ìŠ¤ë ˆë“œ ê¹¨ìš°ê¸°
        with self.buffer_lock:
            self.buffer_not_full.notify_all()
            self.frames_available.notify_all()
        print("ğŸ›‘ Frame Loading Thread ì¢…ë£Œ ìš”ì²­ë¨")
    
    def _continuous_frame_reader(self):
        """
        ğŸ”„ Producer: ì§€ì†ì ìœ¼ë¡œ í”„ë ˆì„ì„ ì½ì–´ì„œ ë²„í¼ì— ì €ì¥
        ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰ë˜ë©° VideoCaptureë¥¼ ë…ì  ì‚¬ìš©
        """
        print("ğŸ“– Start Continuous Frame Reader")
        
        frame_idx = 0
        consecutive_failures = 0
        max_consecutive_failures = 10
        
        try:
            while not self.stop_event.is_set() and frame_idx < self.total_frames:
                # ë²„í¼ í¬ê¸° ì²´í¬ ë° ëŒ€ê¸°
                with self.buffer_lock:
                    while (len(self.frame_buffer) >= self.max_buffer_size and 
                           not self.stop_event.is_set()):
                        self.stats['buffer_waits'] += 1
                        # print(f"â³ í”„ë ˆì„ ë²„í¼ ê°€ë“ì°¸ ({len(self.frame_buffer)}/{self.max_buffer_size}), ëŒ€ê¸° ì¤‘...")
                        self.buffer_not_full.wait(timeout=1.0)
                
                if self.stop_event.is_set():
                    break
                
                # í”„ë ˆì„ ì½ê¸°
                ok, frame_bgr = self.cap.read()
                
                if ok:
                    # ì„±ê³µì ìœ¼ë¡œ ì½ìŒ
                    consecutive_failures = 0
                    
                    # ë²„í¼ì— ì €ì¥
                    with self.buffer_lock:
                        self.frame_buffer[frame_idx] = {
                            'frame': frame_bgr.copy(),
                            'frame_idx': frame_idx
                        }
                        
                        # í†µê³„ ì—…ë°ì´íŠ¸
                        current_buffer_size = len(self.frame_buffer)
                        self.stats['max_buffer_used'] = max(self.stats['max_buffer_used'], 
                                                          current_buffer_size)
                        
                        # Consumerì—ê²Œ í”„ë ˆì„ ì¤€ë¹„ë¨ ì•Œë¦¼
                        self.frames_available.notify_all()
                    
                    frame_idx += 1
                    
                    # # ì£¼ê¸°ì  ìƒíƒœ ì¶œë ¥ (1000 í”„ë ˆì„ë§ˆë‹¤)
                    # if frame_idx % 1000 == 0:
                    #     with self.buffer_lock:
                    #         buffer_size = len(self.frame_buffer)
                    #     print(f"ğŸ“– í”„ë ˆì„ ì½ê¸° ì§„í–‰: {frame_idx}/{self.total_frames} "
                    #           f"(ë²„í¼: {buffer_size}/{self.max_buffer_size})")
                
                else:
                    # ì½ê¸° ì‹¤íŒ¨
                    consecutive_failures += 1
                    self.stats['failed_frames'] += 1
                    
                    # if consecutive_failures >= max_consecutive_failures:
                    #     print(f"ğŸ’¥ ì—°ì† {consecutive_failures}íšŒ í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨, ì¤‘ë‹¨")
                    #     break
                    
                    print(f"âš ï¸ í”„ë ˆì„ {frame_idx} ì½ê¸° ì‹¤íŒ¨ ({consecutive_failures}/{max_consecutive_failures})")
                    frame_idx += 1  # ë‹¤ìŒ í”„ë ˆì„ìœ¼ë¡œ ê³„ì†
                
        except Exception as e:
            print(f"ğŸ’¥ ì—°ì† í”„ë ˆì„ ì½ê¸° ì˜¤ë¥˜: {e}")
        finally:
            print(f"ğŸ“– ì—°ì† í”„ë ˆì„ ì½ê¸° ì¢…ë£Œ: {frame_idx} í”„ë ˆì„ ì²˜ë¦¬ ì™„ë£Œ")
            # Consumerë“¤ì—ê²Œ ì¢…ë£Œ ì•Œë¦¼
            with self.buffer_lock:
                self.frames_available.notify_all()
    
    def _load_batch_frames(self, start_frame, end_frame):
        """
        ğŸ›’ Consumer: ë²„í¼ì—ì„œ í•„ìš”í•œ í”„ë ˆì„ë“¤ì„ êº¼ë‚´ì„œ ë°°ì¹˜ êµ¬ì„±
        ì‚¬ìš©ëœ í”„ë ˆì„ì€ ì¦‰ì‹œ ì‚­ì œí•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í™•ë³´
        """
        batch_size = end_frame - start_frame
        raw_frames = {}
        
        # 1ë‹¨ê³„: ë²„í¼ì—ì„œ í•„ìš”í•œ í”„ë ˆì„ë“¤ ìˆ˜ì§‘
        for frame_idx in range(start_frame, end_frame):
            frame_data = None
            max_wait_attempts = 50  # ìµœëŒ€ 5ì´ˆ ëŒ€ê¸° (100ms Ã— 50)
            
            for attempt in range(max_wait_attempts):
                with self.buffer_lock:
                    if frame_idx in self.frame_buffer:
                        # í”„ë ˆì„ ì°¾ìŒ â†’ ì¦‰ì‹œ êº¼ë‚´ì„œ ì‚­ì œ (í•µì‹¬!)
                        frame_data = self.frame_buffer.pop(frame_idx)
                        
                        # Producerì—ê²Œ ë²„í¼ ê³µê°„ ìƒê¹€ ì•Œë¦¼
                        self.buffer_not_full.notify()
                        break
                    else:
                        # í”„ë ˆì„ ì•„ì§ ì—†ìŒ â†’ ì ì‹œ ëŒ€ê¸°
                        self.frames_available.wait(timeout=0.1)
                
                if self.stop_event.is_set():
                    break
            
            if frame_data is not None:
                raw_frames[frame_idx] = frame_data['frame']
            else:
                print(f"âš ï¸ í”„ë ˆì„ {frame_idx} ë²„í¼ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ (íƒ€ì„ì•„ì›ƒ)")
                self.stats['failed_frames'] += 1
        
        if not raw_frames:
            print("ğŸ’¥ ë²„í¼ì—ì„œ ì½ì€ í”„ë ˆì„ì´ ì—†ìŒ")
            return None
        
        # print(f"   ğŸ›’ ë²„í¼ì—ì„œ ìˆ˜ì§‘: {len(raw_frames)}/{batch_size} í”„ë ˆì„")
        
        # 2ë‹¨ê³„: ë³‘ë ¬ ì „ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        processed_frames = {}
        lock = threading.Lock()
        
        def preprocess_single_frame(frame_idx, frame_bgr):
            """ë‹¨ì¼ í”„ë ˆì„ ì „ì²˜ë¦¬ (ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰)"""
            try:
                # RGB ë³€í™˜ ë° ì „ì²˜ë¦¬ (CPU ì§‘ì•½ì )
                frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
                frame_rgb = preprocess_image(frame_rgb, self.args)
                
                # PIL Imageë¡œ ë³€í™˜
                pil_frame = Image.fromarray(frame_rgb)
                
                # ìŠ¤ë ˆë“œ ì„¸ì´í”„í•˜ê²Œ ì €ì¥
                with lock:
                    processed_frames[frame_idx] = {
                        'pil_frame': pil_frame,
                        'original_frame': frame_bgr,
                        'success': True
                    }
                    
            except Exception as e:
                with lock:
                    processed_frames[frame_idx] = {'success': False, 'error': str(e)}
                print(f"ğŸ’¥ í”„ë ˆì„ {frame_idx} ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        
        # ë³‘ë ¬ ì „ì²˜ë¦¬ ì‹¤í–‰
        max_workers = min(self.args.frame_loading_threads, len(raw_frames))
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = [
                executor.submit(preprocess_single_frame, frame_idx, frame_bgr) 
                for frame_idx, frame_bgr in raw_frames.items()
            ]
            concurrent.futures.wait(futures)
        
        # 3ë‹¨ê³„: ê²°ê³¼ ì •ë¦¬ (ì¸ë±ìŠ¤ ìˆœì„œëŒ€ë¡œ)
        batch_frames = []
        batch_indices = []
        batch_original_frames = []
        
        loaded_count = 0
        for frame_idx in range(start_frame, end_frame):
            if frame_idx in processed_frames and processed_frames[frame_idx]['success']:
                batch_frames.append(processed_frames[frame_idx]['pil_frame'])
                batch_indices.append(frame_idx)
                batch_original_frames.append(processed_frames[frame_idx]['original_frame'])
                loaded_count += 1
        
        if loaded_count == 0:
            return None
        
        return {
            'batch_frames': batch_frames,
            'batch_indices': batch_indices,
            'batch_original_frames': batch_original_frames,
            'loaded_count': loaded_count,
            'total_count': batch_size
        }
    
    # ANCHOR Frame Loading Thread Run
    def run(self):
        """ë©”ì¸ ë°°ì¹˜ ë¡œë”© ë£¨í”„ (Consumer)"""
        print("\nğŸš€ Frame Loading Thread ì‹œì‘!")
        
        # ë‚´ë¶€ í”„ë ˆì„ ì½ê¸° ìŠ¤ë ˆë“œ ì‹œì‘
        if not self.reader_started:
            self.reader_thread.start()
            self.reader_started = True
        
        try:
            while not self.stop_event.is_set() and self.current_frame < self.total_frames:
                # Queueê°€ ê°€ë“ ì°¬ ê²½ìš° ëŒ€ê¸°
                if self.batch_queue.qsize() >= self.max_queue_size:
                    if not self.queue_full_print:
                        # print(f"â³ Queue ê°€ë“ì°¸ ({self.batch_queue.qsize()}/{self.max_queue_size}), ì ì‹œ ëŒ€ê¸°...")
                        self.queue_full_print = True
                    time.sleep(0.1)
                    continue
                
                # ë°°ì¹˜ í”„ë ˆì„ ë¡œë“œ
                batch_start = self.current_frame
                batch_end = min(batch_start + self.batch_size, self.total_frames)
                
                batch_data = self._load_batch_frames(batch_start, batch_end)
                
                if batch_data is not None:
                    # Queueì— ë°°ì¹˜ ë°ì´í„° ì €ì¥
                    self.batch_queue.put(batch_data, timeout=5.0)
                    self.stats['total_batches_loaded'] += 1
                    self.stats['total_frames_loaded'] += len(batch_data['batch_indices'])
                    
                    # print(f"âœ… ë°°ì¹˜ ë¡œë”© ì™„ë£Œ: {len(batch_data['batch_indices'])} í”„ë ˆì„ â†’ Queueì— ì €ì¥")
                else:
                    print(f"âŒ ë°°ì¹˜ ë¡œë”© ì‹¤íŒ¨: í”„ë ˆì„ {batch_start}-{batch_end-1}")
                
                self.current_frame = batch_end
                self.queue_full_print = False
                
            print(f"ğŸ”„ í˜„ì¬ í”„ë ˆì„: {self.current_frame}/{self.total_frames}")
                
        except Exception as e:
            print(f"ğŸ’¥ Frame Loading Thread ì˜¤ë¥˜: {e}")
        finally:
            # ì¢…ë£Œ ì‹ í˜¸ë¥¼ Queueì— ë°˜ë“œì‹œ ì „ë‹¬ (Queueê°€ ë¹Œ ë•Œê¹Œì§€ ëŒ€ê¸°)
            print("ğŸ“¤ ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡ ì¤€ë¹„ ì¤‘...")
            queue_full_warning_shown = False
            while True:
                try:
                    self.batch_queue.put(None, timeout=1.0)  # Noneì€ ì¢…ë£Œ ì‹ í˜¸
                    print("ğŸ Frame Loading Thread ì¢…ë£Œ ì‹ í˜¸ ì „ë‹¬ ì™„ë£Œ!")
                    break
                except queue.Full:
                    if not queue_full_warning_shown:
                        print("â³ Queue ê°€ë“ì°¸, ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡ì„ ìœ„í•´ ëŒ€ê¸° ì¤‘...")
                        queue_full_warning_shown = True
                    time.sleep(0.1)
            
            # ë‚´ë¶€ ìŠ¤ë ˆë“œ ì •ë¦¬
            if self.reader_started and self.reader_thread.is_alive():
                print("ğŸ›‘ ë‚´ë¶€ í”„ë ˆì„ ì½ê¸° ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°...")
                self.reader_thread.join(timeout=3.0)
                if self.reader_thread.is_alive():
                    print("âš ï¸ ë‚´ë¶€ í”„ë ˆì„ ì½ê¸° ìŠ¤ë ˆë“œ ê°•ì œ ì¢…ë£Œ íƒ€ì„ì•„ì›ƒ")
                else:
                    print("âœ… ë‚´ë¶€ í”„ë ˆì„ ì½ê¸° ìŠ¤ë ˆë“œ ì •ìƒ ì¢…ë£Œ")
            
            # VideoCapture ì •ë¦¬
            if self.cap.isOpened():
                self.cap.release()
                print("ğŸ¬ VideoCapture í•´ì œ ì™„ë£Œ")
            
            # ìµœì¢… í†µê³„ ì¶œë ¥
            print(f"ğŸ“ˆ Frame Loading Thread ìµœì¢… í†µê³„:")
            print(f"   - ë¡œë“œëœ ë°°ì¹˜ ìˆ˜: {self.stats['total_batches_loaded']}")
            print(f"   - ë¡œë“œëœ í”„ë ˆì„ ìˆ˜: {self.stats['total_frames_loaded']}")
            print(f"   - ì‹¤íŒ¨í•œ í”„ë ˆì„ ìˆ˜: {self.stats['failed_frames']}")
            print(f"   - ë²„í¼ ëŒ€ê¸° íšŸìˆ˜: {self.stats['buffer_waits']}")
            print(f"   - ìµœëŒ€ ë²„í¼ ì‚¬ìš©ëŸ‰: {self.stats['max_buffer_used']}/{self.max_buffer_size}")
            
            # ë²„í¼ íš¨ìœ¨ì„± ê³„ì‚°
            if self.stats['total_frames_loaded'] > 0:
                success_rate = (self.stats['total_frames_loaded'] / 
                              (self.stats['total_frames_loaded'] + self.stats['failed_frames'])) * 100
                buffer_efficiency = (self.stats['max_buffer_used'] / self.max_buffer_size) * 100
                print(f"   - í”„ë ˆì„ ë¡œë”© ì„±ê³µë¥ : {success_rate:.1f}%")
                print(f"   - ë²„í¼ ì‚¬ìš© íš¨ìœ¨ì„±: {buffer_efficiency:.1f}%")
    



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def preprocess_image(image, args):
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜"""
    # ì´ë¯¸ì§€ë¥¼ float32ë¡œ ë³€í™˜
    img = image.astype(np.float32)
    
    # ì„ ëª…ë„ í–¥ìƒ
    if args.sharpen > 0:
        kernel = np.array([[-1,-1,-1],
                          [-1, 9,-1],
                          [-1,-1,-1]]) * args.sharpen
        img = cv2.filter2D(img, -1, kernel)
    
    # ëŒ€ë¹„ ì¡°ì •
    if args.contrast != 1.0:
        img = cv2.convertScaleAbs(img, alpha=args.contrast, beta=0)
    
    # ë°ê¸° ì¡°ì •
    if args.brightness != 0:
        img = cv2.convertScaleAbs(img, alpha=1.0, beta=args.brightness)
    
    # ë…¸ì´ì¦ˆ ì œê±°
    if args.denoise > 0:
        img = cv2.fastNlMeansDenoisingColored(img, None, 
                                             h=args.denoise*10, 
                                             hColor=args.denoise*10, 
                                             templateWindowSize=7, 
                                             searchWindowSize=21)
    
    # ê°’ ë²”ìœ„ë¥¼ 0-255ë¡œ ì œí•œ
    img = np.clip(img, 0, 255).astype(np.uint8)
    return img

# ANCHOR Detection Result Processing
def process_batch_results(batch_detected_objects, batch_indices, batch_original_frames, 
                         tracker, args, fps, palette, person_class_id,
                         # ìƒíƒœ ë³€ìˆ˜ë“¤
                         track_history, track_side, track_color, 
                         forward_cnt, backward_cnt, current_occupancy, current_congestion,
                         last_update_time, heatmap, last_save_frame, log_buffer,
                         # I/O ê´€ë ¨
                         output_dir, out, log_file,
                         # ë¼ì¸ í¬ë¡œì‹± ê´€ë ¨
                         p1, p2, p1_input, p2_input, seg_dx, seg_dy, seg_len2,
                         width, height, output_width, output_height, scale_x, scale_y,
                         # Progress bar & Queue monitoring
                         pbar=None, frame_queue=None, result_queue=None, pipeline_stats=None,
                         # ROI Access Detection
                         roi_manager=None,
                         # Basic Detection Area
                         detection_area_polygon=None):
    """Batch ê²°ê³¼ë¥¼ ê°œë³„ í”„ë ˆì„ìœ¼ë¡œ ì²˜ë¦¬ (CPU ë°ì´í„° ê¸°ë°˜)"""
    
    updated_state = {
        'forward_cnt': forward_cnt,
        'backward_cnt': backward_cnt,
        'current_occupancy': current_occupancy,
        'current_congestion': current_congestion,
        'last_update_time': last_update_time,
        'last_save_frame': last_save_frame
    }
    
    for detected_objects, frame_idx, original_frame in zip(batch_detected_objects, batch_indices, batch_original_frames):
        # ì‹œê°„ ê³„ì‚°
        current_time = frame_idx / fps
        hours = int(current_time // 3600)
        minutes = int((current_time % 3600) // 60)
        seconds = int(current_time % 60)
        milliseconds = int((current_time % 1) * 1000)
        time_str = f"{hours:02d}:{minutes:02d}:{seconds:02d}.{milliseconds:03d}"
        
        # ğŸš€ ObjectMeta ì´ë¯¸ ì¤€ë¹„ë¨! (InferenceThreadì—ì„œ ë³€í™˜ + í•„í„°ë§ ì™„ë£Œ)
        # detected_objectsëŠ” ì´ë¯¸ í•„í„°ë§ëœ ObjectMeta ë¦¬ìŠ¤íŠ¸
        
        # Tracker ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        tracked_objects = tracker.update(detected_objects, original_frame, "None")
        
        # ROI Access Detection ì—…ë°ì´íŠ¸
        roi_tracks_status = {}
        if roi_manager is not None:
            roi_manager.update(tracked_objects, frame_idx, original_frame.shape)
            roi_tracks_status = roi_manager.get_roi_tracks_by_status()
        
        # ğŸ¨ ëª¨ë“  ì¶”ì ëœ ê°ì²´ë“¤ì„ ì˜¤ë²„ë ˆì´ì— í‘œì‹œ
        all_objects_for_overlay = tracked_objects
        
        # ğŸ” ë””ë²„ê¹…: ìµœì¢… ì˜¤ë²„ë ˆì´ ê°ì²´ í™•ì¸
        if _debug_frame_count <= _max_debug_frames:
            print(f"   - ì¶”ì ëœ ê°ì²´: {len(tracked_objects)}ê°œ")
            print(f"   - ìµœì¢… ì˜¤ë²„ë ˆì´ ê°ì²´: {len(all_objects_for_overlay)}ê°œ")
            
            # track_id ë¶€ì—¬ ìƒí™© í™•ì¸
            tracked_with_id = [obj for obj in tracked_objects if obj.track_id is not None]
            print(f"   - track_id ë¶€ì—¬ëœ ê°ì²´: {len(tracked_with_id)}ê°œ")
            print("-" * 40)
        
        # ê¸°ì¡´ ë³€ìˆ˜ë“¤ ì¶”ì¶œ (í˜¸í™˜ì„± ìœ ì§€)
        if tracked_objects:
            boxes_xywh = []
            for obj in tracked_objects:
                x1, y1, x2, y2 = obj.box  # xyxy
                cx, cy = (x1 + x2) / 2, (y1 + y2) / 2
                w, h = x2 - x1, y2 - y1
                boxes_xywh.append([cx, cy, w, h])
            boxes_xywh = np.array(boxes_xywh)
            
            class_ids = np.array([obj.class_id for obj in tracked_objects])
            track_ids = np.array([obj.track_id for obj in tracked_objects])
        else:
            boxes_xywh = np.empty((0, 4))
            class_ids = np.empty(0, int)
            track_ids = np.empty(0, int)

        # ğŸ¯ ë¡œê¹… ì²˜ë¦¬ (ëª¨ë“  í´ë˜ìŠ¤ í¬í•¨, confidence >= medium_threshì¸ ê°ì²´ë§Œ ë¡œê¹…)
        if log_file is not None:
            class_counts = defaultdict(int)
            # medium_thresh ì´ìƒì˜ ê°ì²´ë§Œ ë¡œê¹… (ì €ì‹ ë¢°ë„ ê°ì²´ëŠ” ë¡œê¹…ì—ì„œ ì œì™¸)
            valid_objects = [obj for obj in tracked_objects if obj.confidence >= args.medium_conf_thresh]
            valid_class_ids = [obj.class_id for obj in valid_objects]
            valid_track_ids = [obj.track_id for obj in valid_objects]
            
            for cid in valid_class_ids:
                if cid >= 0:  # ìœ íš¨í•œ í´ë˜ìŠ¤ IDë§Œ
                    class_counts[cid] += 1

            for obj in valid_objects:
                if obj.class_id >= 0:  # ìœ íš¨í•œ í´ë˜ìŠ¤ IDë§Œ
                    class_name = obj.class_name
                    class_count = class_counts[obj.class_id]
                    log_entry = f"{time_str},{class_name},{obj.track_id},{class_count}\n"
                    log_buffer.append(log_entry)
                    if len(log_buffer) >= 100:
                        log_file.writelines(log_buffer)
                        log_file.flush()
                        log_buffer.clear()

        # ì‹œê°í™” - ì¶œë ¥ í•´ìƒë„ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        frame_rgb = cv2.cvtColor(original_frame, cv2.COLOR_BGR2RGB)
        
        # ì¶œë ¥ í•´ìƒë„ì™€ ì…ë ¥ í•´ìƒë„ê°€ ë‹¤ë¥´ë©´ ë¦¬ì‚¬ì´ì¦ˆ
        if output_width != width or output_height != height:
            frame_rgb = cv2.resize(frame_rgb, (output_width, output_height), interpolation=cv2.INTER_LINEAR)
        
        annotated = frame_rgb.copy()
        
        # ê¸°ë³¸ ê°ì§€ ì˜ì—­ ì‹œê°í™” (ì¶œë ¥ í•´ìƒë„ì— ë§ê²Œ ìŠ¤ì¼€ì¼ë§)
        if detection_area_polygon is not None:
            annotated = draw_detection_area(annotated, detection_area_polygon, scale_x, scale_y)    
        
        # ê°ì²´ ì˜¤ë²„ë ˆì´ (ìŠ¤ì¼€ì¼ë§ëœ ì¢Œí‘œë¡œ)
        scaled_objects = []
        if tracked_objects:
            # ê°ì²´ ì¢Œí‘œë¥¼ ì¶œë ¥ í•´ìƒë„ì— ë§ê²Œ ìŠ¤ì¼€ì¼ë§
            for obj in tracked_objects:
                scaled_obj = ObjectMeta(
                    box=[obj.box[0] * scale_x, obj.box[1] * scale_y, 
                         obj.box[2] * scale_x, obj.box[3] * scale_y],
                    mask=None,  # ë§ˆìŠ¤í¬ëŠ” ë³„ë„ ì²˜ë¦¬
                    confidence=obj.confidence,
                    class_id=obj.class_id,
                    class_name=obj.class_name,
                    track_id=obj.track_id
                )
                
                # ë§ˆìŠ¤í¬ê°€ ìˆìœ¼ë©´ ì¶œë ¥ í•´ìƒë„ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                if obj.mask is not None:
                    scaled_obj.mask = cv2.resize(obj.mask.astype(np.float32), 
                                               (output_width, output_height), 
                                               interpolation=cv2.INTER_LINEAR)
                
                scaled_objects.append(scaled_obj)
            
            annotated = draw_objects_overlay(annotated, scaled_objects, palette)

        # ROI ì‹œê°í™” (ì¶œë ¥ í•´ìƒë„ì— ë§ê²Œ ìŠ¤ì¼€ì¼ë§)
        if roi_manager is not None:
            # ROI polygonì„ ì¶œë ¥ í•´ìƒë„ì— ë§ê²Œ ìŠ¤ì¼€ì¼ë§
            scaled_roi_polygons = []
            for polygon in roi_manager.roi_polygons:
                coords = np.array(polygon.exterior.coords)
                scaled_coords = coords * [scale_x, scale_y]
                from shapely.geometry import Polygon
                scaled_polygon = Polygon(scaled_coords)
                scaled_roi_polygons.append(scaled_polygon)
            
            # ROI polygon ê·¸ë¦¬ê¸° (ìŠ¤ì¼€ì¼ë§ëœ ì¢Œí‘œë¡œ)
            annotated = draw_roi_polygons(annotated, scaled_roi_polygons, 
                                        roi_manager.roi_names, roi_manager.roi_stats)
        
            # ğŸ¯ ROIì— ìˆëŠ” ê°ì²´ë“¤ ìƒíƒœë³„ í•˜ì´ë¼ì´íŠ¸ (ìŠ¤ì¼€ì¼ë§ëœ ê°ì²´ë¡œ)
            if tracked_objects:
                annotated = highlight_roi_objects(annotated, scaled_objects, 
                                                roi_tracks_status, palette)

        # Occupancy ì—…ë°ì´íŠ¸
        raw_occupancy = int(np.sum(class_ids == person_class_id))
        if current_time - updated_state['last_update_time'] >= 1.0:
            updated_state['last_update_time'] = current_time
            updated_state['current_occupancy'] = raw_occupancy
            updated_state['current_congestion'] = int(min(raw_occupancy / max(args.max_people, 1), 1.0) * 100)

        line_crossed_this_frame = False

        # íˆíŠ¸ë§µ ë° ë¼ì¸ í¬ë¡œì‹± ì²˜ë¦¬
        for obj in tracked_objects:
            if obj.track_id == -1 or obj.class_id != person_class_id:
                continue

            x1, y1, x2, y2 = obj.box
            cx, cy = (x1 + x2) / 2, (y1 + y2) / 2
            ix, iy = int(cx), int(cy)
            
            # íˆíŠ¸ë§µ ì—…ë°ì´íŠ¸
            if 0 <= iy < height and 0 <= ix < width:
                radius = 10
                for dy in range(-radius, radius + 1):
                    for dx in range(-radius, radius + 1):
                        if dx*dx + dy*dy <= radius*radius:
                            ny, nx = iy + dy, ix + dx
                            if 0 <= ny < height and 0 <= nx < width:
                                intensity = 1.0 * (1.0 - ((dx*dx + dy*dy) / (radius*radius)))
                                heatmap[ny, nx] += intensity

            # íŠ¸ë˜í‚¹ ì»¬ëŸ¬ ì„¤ì •
            if obj.track_id not in track_color:
                track_color[obj.track_id] = palette.by_idx(obj.track_id).as_bgr()

            # ë¼ì¸ í¬ë¡œì‹± ì²´í¬ (ì…ë ¥ í•´ìƒë„ ê¸°ì¤€ ì¢Œí‘œ ì‚¬ìš©)
            if p1_input is not None and p2_input is not None:
                side_now = point_side((cx, cy), p1_input, p2_input)
                t = ((cx - p1_input[0]) * seg_dx + (cy - p1_input[1]) * seg_dy) / seg_len2
                inside = 0.0 <= t <= 1.0

                side_prev = track_side.get(obj.track_id, side_now)
                if inside and (side_prev * side_now < 0):
                    line_crossed_this_frame = True
                    if side_prev < 0 < side_now:
                        updated_state['forward_cnt'] += 1
                    elif side_prev > 0 > side_now:
                        updated_state['backward_cnt'] += 1
                if inside and side_now != 0:
                    track_side[obj.track_id] = side_now

        # ë¼ì¸ ê·¸ë¦¬ê¸° (ì¶œë ¥ í•´ìƒë„ì— ë§ê²Œ ìŠ¤ì¼€ì¼ë§)
        if p1 is not None and p2 is not None:
            line_thickness = 8
            
            if line_crossed_this_frame:
                cv2.line(annotated, p1, p2, (255, 0, 0), line_thickness)
            else:
                cv2.line(annotated, p1, p2, (255, 255, 255), line_thickness)

            mid_x, mid_y = (p1[0] + p2[0]) // 2, (p1[1] + p2[1]) // 2
            dx, dy = p2[0] - p1[0], p2[1] - p1[1]
            perp_x, perp_y = -dy, dx
            length = 50
            mag = (perp_x**2 + perp_y**2) ** 0.5 or 1
            perp_x, perp_y = int(perp_x / mag * length), int(perp_y / mag * length)
            arrow_start, arrow_end = (mid_x, mid_y), (mid_x + perp_x, mid_y + perp_y)
            cv2.arrowedLine(annotated, arrow_start, arrow_end, (0, 255, 0), line_thickness, tipLength=0.6)

        # Overlay ì •ë³´ ê·¸ë¦¬ê¸° (ROI ì •ë³´ ì¶”ê°€)
        overlay = [
            f"[1] Congestion : {updated_state['current_congestion']:3d} %",
            f"[2] Crossing   : forward {updated_state['forward_cnt']} | backward {updated_state['backward_cnt']}",
            f"[3] Occupancy  : {updated_state['current_occupancy']}",
            f"[4] Time      : {time_str}"
        ]
        
        # ROI ì ‘ê·¼ íšŸìˆ˜ ì •ë³´ ì¶”ê°€
        if roi_manager is not None:
            for roi_name, roi_stat in roi_manager.roi_stats.items():
                overlay.append(f"[ROI] {roi_name}: {roi_stat['total_access']} accesses")
        
        # ì˜¤ë²„ë ˆì´ í…ìŠ¤íŠ¸ í¬ê¸° (0~1 ì •ê·œí™” ì¢Œí‘œë¥¼ ì¶œë ¥ í•´ìƒë„ì— ë§ê²Œ ìŠ¤ì¼€ì¼ë§)
        # 1920x1080 ê¸°ì¤€: x0=30, y0=60, dy=50, padding=10
        # ì •ê·œí™”: x0=30/1920=0.0156, y0=60/1080=0.0556, dy=50/1080=0.0463, padding=10/1920=0.0052
        
        # ì •ê·œí™”ëœ ì¢Œí‘œ (0~1 ë²”ìœ„)
        norm_x0, norm_y0, norm_dy, norm_padding = 0.0156, 0.0556, 0.0463, 0.0052
        
        # ì¶œë ¥ í•´ìƒë„ì— ë§ê²Œ ìŠ¤ì¼€ì¼ë§
        x0 = int(norm_x0 * output_width)
        y0 = int(norm_y0 * output_height)
        dy = int(norm_dy * output_height)
        padding = int(norm_padding * output_width)
        
        # í°íŠ¸ í¬ê¸°ë„ ì¶œë ¥ í•´ìƒë„ì— ë§ê²Œ ìŠ¤ì¼€ì¼ë§
        # 1920x1080 ê¸°ì¤€: font_scale=1, font_thickness=2
        # ì •ê·œí™”: font_scale=1, font_thickness=2 (ê¸°ë³¸ê°’ ìœ ì§€, í•„ìš”ì‹œ ì¡°ì • ê°€ëŠ¥)
        base_font_scale = 1.0
        base_font_thickness = 2
        
        # ì¶œë ¥ í•´ìƒë„ì— ë”°ë¥¸ í°íŠ¸ í¬ê¸° ì¡°ì • (1920x1080 ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”)
        scale_factor = min(output_width / 1920, output_height / 1080)
        font_scale = base_font_scale * scale_factor
        font_thickness = max(1, int(base_font_thickness * scale_factor))
        
        font = cv2.FONT_HERSHEY_SIMPLEX
        
        max_width = 0
        for txt in overlay:
            (tw, th), _ = cv2.getTextSize(txt, font, font_scale, font_thickness)
            max_width = max(max_width, tw)
        rect_x1, rect_y1 = x0 - padding, y0 - th - padding
        rect_x2, rect_y2 = x0 + max_width + padding, y0 + (len(overlay) - 1) * dy + padding
        overlay_rect = annotated.copy()
        cv2.rectangle(overlay_rect, (rect_x1, rect_y1), (rect_x2, rect_y2), (0, 0, 0), -1)
        annotated = cv2.addWeighted(overlay_rect, 0.4, annotated, 0.6, 0)
        for i, txt in enumerate(overlay):
            cv2.putText(annotated, txt, (x0, y0 + i * dy),
                        font, font_scale, (255, 255, 255), font_thickness, cv2.LINE_AA)

        # íˆíŠ¸ë§µ minimap (ì¶œë ¥ í•´ìƒë„ì— ë§ê²Œ ì¡°ì •)
        blur = cv2.GaussianBlur(heatmap, (0, 0), sigmaX=15, sigmaY=15)
        norm = cv2.normalize(blur, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
        color_hm = cv2.applyColorMap(norm, cv2.COLORMAP_JET)
        color_hm = cv2.cvtColor(color_hm, cv2.COLOR_BGR2RGB)

        # ë¯¸ë‹ˆë§µ í¬ê¸°ë¥¼ ì¶œë ¥ í•´ìƒë„ì— ë§ê²Œ ì¡°ì • (0~1 ì •ê·œí™” ì¢Œí‘œ ì‚¬ìš©)
        # 1920x1080 ê¸°ì¤€: mini_w=400, margin=20
        # ì •ê·œí™”: mini_w=400/1920=0.2083, margin=20/1920=0.0104
        
        # ì •ê·œí™”ëœ í¬ê¸° (0~1 ë²”ìœ„)
        norm_mini_width = 0.2083  # í™”ë©´ ë„ˆë¹„ì˜ 20.83%
        norm_margin = 0.0104      # í™”ë©´ ë„ˆë¹„ì˜ 1.04%
        
        # ì¶œë ¥ í•´ìƒë„ì— ë§ê²Œ ìŠ¤ì¼€ì¼ë§
        mini_w = int(norm_mini_width * output_width)
        mini_h = int(output_height * mini_w / output_width)
        margin = int(norm_margin * output_width)
        
        mini_map = cv2.resize(color_hm, (mini_w, mini_h))

        # ë¯¸ë‹ˆë§µ ìœ„ì¹˜ ê³„ì‚° (ìš°ìƒë‹¨)
        x_start = output_width - mini_w - margin
        y_start = margin
        
        # ê²½ê³„ ì²´í¬
        if x_start >= 0 and y_start >= 0 and x_start + mini_w <= output_width and y_start + mini_h <= output_height:
            roi = annotated[y_start:y_start + mini_h, x_start:x_start + mini_w]
            blended = cv2.addWeighted(mini_map, 0.6, roi, 0.4, 0)
            annotated[y_start:y_start + mini_h, x_start:x_start + mini_w] = blended

        # ì¤‘ê°„ ì €ì¥
        if frame_idx - updated_state['last_save_frame'] >= args.save_interval:
            snapshot_path = os.path.join(output_dir, f"intermediate_{frame_idx:06d}_{time_str.replace(':', '-')}.jpg")
            cv2.imwrite(snapshot_path, cv2.cvtColor(annotated, cv2.COLOR_RGB2BGR))
            updated_state['last_save_frame'] = frame_idx
            print(f"\nì¤‘ê°„ ì €ì¥ ì™„ë£Œ: {snapshot_path}")

        # ë¹„ë””ì˜¤ ì¶œë ¥
        out.write(cv2.cvtColor(annotated, cv2.COLOR_RGB2BGR))
        
        # Progress bar ì¦‰ì‹œ ì—…ë°ì´íŠ¸ (í”„ë ˆì„ ë‹¨ìœ„) + ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ë°˜ì˜
        if pbar is not None:
            pbar.update(1)
            
            # ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ì„ postfixë¡œ í‘œì‹œ
            if frame_queue is not None and result_queue is not None and pipeline_stats is not None:
                frame_queue_size = frame_queue.qsize()
                result_queue_size = result_queue.qsize()
                
                # FPS ê³„ì‚°
                elapsed_time = time.time() - pipeline_stats['start_time']
                avg_fps = pipeline_stats['processed_frames'] / elapsed_time if elapsed_time > 0 else 0
                
                # ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ì„ postfixë¡œ ì—…ë°ì´íŠ¸
                pbar.set_postfix({
                    'FPS': f'{avg_fps:.1f}',
                    'Frame_Q': frame_queue_size,
                    'Result_Q': result_queue_size
                    # 'Occupancy': updated_state['current_occupancy'],
                    # 'Congestion': f"{updated_state['current_congestion']}%",
                    # 'Forward': updated_state['forward_cnt'],
                    # 'Backward': updated_state['backward_cnt']
                })
    
    return updated_state

def main() -> None:
    args = parse_args()
    # Hybrid VP íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’ 10, 10)
    KEY_INT = getattr(args, 'key_int', 10)
    HOLD_FR = getattr(args, 'hold', 10)
    drift_max = HOLD_FR  # ì—°ì† ê²€ì¶œ ì‹¤íŒ¨ì‹œ ë¦¬ì…‹
    drift_count = 0
    
    # object í´ë˜ìŠ¤ëŠ” ë”°ë¡œ ë§Œë“¤ì§€ ì•ŠìŒ (ì €ì‹ ë¢°ë„ detectionì€ ì„ì‹œë¡œ low_objectë¡œ ì²˜ë¦¬)

    # ì…ë ¥ íŒŒì¼ ì´ë¦„ì—ì„œ í™•ì¥ìë¥¼ ì œì™¸í•œ ê¸°ë³¸ ì´ë¦„ ì¶”ì¶œ
    base_name = os.path.splitext(os.path.basename(args.source))[0]
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    if args.output is None:
        output_dir = os.path.join(os.path.dirname(args.source), base_name)
    else:
        output_dir = args.output
    
    # ê¸°ì¡´ ì¶œë ¥ ë””ë ‰í† ë¦¬ê°€ ìˆë‹¤ë©´ ì‚­ì œ
    if os.path.exists(output_dir):
        import shutil
        print(f"ê¸°ì¡´ ì¶œë ¥ ë””ë ‰í† ë¦¬ ì‚­ì œ ì¤‘: {output_dir}")
        shutil.rmtree(output_dir)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    print(f"ìƒˆë¡œìš´ ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±: {output_dir}")
    os.makedirs(output_dir, exist_ok=True)
    
    # ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ ì„¤ì •
    output_video = os.path.join(output_dir, f"{base_name}_output.mp4")

    # ë¡œê·¸ íŒŒì¼ ì„¤ì •
    log_file = None
    if args.log_detections:
        log_path = os.path.join(output_dir, "label.txt")
        log_file = open(log_path, "w", encoding="utf-8")
        log_file.write("Frame_Time,Class,TrackID,Class_Count\n")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ I/O setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
    cap = cv2.VideoCapture(args.source)
    if not cap.isOpened():
        raise FileNotFoundError(f"Cannot open video {args.source}")

    # ì…ë ¥ í•´ìƒë„
    input_width, input_height = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps, total_frames = cap.get(cv2.CAP_PROP_FPS), int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # ğŸ”¥ limit_frameì—ì„œ ì¤‘ë‹¨í•˜ë„ë¡ ì œí•œ
    total_frames = min(total_frames, args.limit_frame)
    print(f"ğŸ“¹ í”„ë ˆì„ ì²˜ë¦¬ ì œí•œ: {total_frames}í”„ë ˆì„ê¹Œì§€ ì²˜ë¦¬ (limit: {args.limit_frame})")
    
    # ì¶œë ¥ í•´ìƒë„ ì„¤ì • (argsì—ì„œ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ì…ë ¥ í•´ìƒë„ ì‚¬ìš©)
    output_width = args.output_width if args.output_width is not None else input_width
    output_height = args.output_height if args.output_height is not None else input_height
    
    # ìŠ¤ì¼€ì¼ë§ ë¹„ìœ¨ ê³„ì‚°
    scale_x = output_width / input_width
    scale_y = output_height / input_height
    
    print(f"\nğŸ“º í•´ìƒë„ ì„¤ì •:")
    print(f"   - ì…ë ¥ í•´ìƒë„: {input_width} x {input_height}")
    print(f"   - ì¶œë ¥ í•´ìƒë„: {output_width} x {output_height}")
    print(f"   - ìŠ¤ì¼€ì¼ë§ ë¹„ìœ¨: x={scale_x:.3f}, y={scale_y:.3f}")
    
    # ê¸°ì¡´ ë³€ìˆ˜ëª… í˜¸í™˜ì„±ì„ ìœ„í•´ width, heightëŠ” ì…ë ¥ í•´ìƒë„ë¡œ ìœ ì§€ (ë‚´ë¶€ ë¡œì§ìš©)
    width, height = input_width, input_height

    # Select frames to process
    frames_to_process = range(total_frames)
    
    # ğŸš€ Pipeline ì²˜ë¦¬ ì„¤ì •
    batch_size = args.batch_size
    total_batches = (total_frames + batch_size - 1) // batch_size
    max_queue_size = 3  # Queue ìµœëŒ€ í¬ê¸° (ë©”ëª¨ë¦¬ ì œì–´)
    
    print(f"\nğŸš€ Pipeline ì²˜ë¦¬ ì‹œì‘: {total_frames} í”„ë ˆì„ì„ {batch_size} ë‹¨ìœ„ë¡œ {total_batches} batch ì²˜ë¦¬")
    # print(f"ğŸ“¦ Queue ê¸°ë°˜ ë³‘ë ¬ ì²˜ë¦¬: Frame Loading Thread + Inference Pipeline")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸš€ 3ë‹¨ê³„ Pipeline Queue ë° Thread ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
    frame_queue = queue.Queue(maxsize=max_queue_size)    # Frame Loading â†’ Inference
    result_queue = queue.Queue(maxsize=max_queue_size)   # Inference â†’ Main
    
    print(f"\nğŸ”— 3ë‹¨ê³„ Pipeline êµ¬ì„±:")
    print(f"   Stage 1: Frame Loading Thread â†’ Frame Queue")
    print(f"   Stage 2: Inference Thread â†’ Result Queue") 
    print(f"   Stage 3: Main Thread (Process Results)")
    
    # Frame Loading Thread ì‹œì‘
    frame_loader = FrameLoadingThread(
        video_source=args.source,
        total_frames=total_frames,
        batch_size=batch_size,
        args=args,
        batch_queue=frame_queue,  # frame_queueë¡œ ë³€ê²½
        max_queue_size=max_queue_size
    )
    frame_loader.start()
    # print(f"ğŸ¬ Stage 1 ì‹œì‘: Frame Loading Thread (PID: {frame_loader.ident})")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Reference Data Loading â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
    reference_data = load_reference_pairs_from_folder(args.reference_img_path, args.names)
    
    vp_classes = reference_data['vp_classes']
    tp_classes = reference_data['tp_classes']
    vp_data = reference_data['vp_data']
    vp_images = reference_data['vp_images']
    reference_files = reference_data['reference_files']
    
    # ğŸ¨ VP í´ë˜ìŠ¤ë“¤ì˜ ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ìƒì„±
    for i, (class_name, img) in enumerate(zip(vp_classes, vp_images)):
        if class_name in reference_files:
            # í•´ë‹¹ í´ë˜ìŠ¤ì˜ ë°”ìš´ë”© ë°•ìŠ¤ ê°€ì ¸ì˜¤ê¸°  
            bboxes = vp_data['bboxes'][i]
            class_ids = vp_data['cls'][i]
            
            reference_overlay = img.copy()
            
            for j, (bbox, class_id) in enumerate(zip(bboxes, class_ids)):
                x1, y1, x2, y2 = map(int, bbox)
                
                # ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ë…¹ìƒ‰)
                cv2.rectangle(reference_overlay, (x1, y1), (x2, y2), (0, 255, 0), 2)
                
                # í´ë˜ìŠ¤ ë¼ë²¨ ê·¸ë¦¬ê¸°
                if class_id < len(args.names):
                    class_name_label = args.names[class_id]
                    label = f"{class_name_label} ({j+1})"
                    
                    # í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚°
                    font = cv2.FONT_HERSHEY_SIMPLEX
                    font_scale = 0.6
                    thickness = 2
                    (text_w, text_h), baseline = cv2.getTextSize(label, font, font_scale, thickness)
                    
                    # ë¼ë²¨ ë°°ê²½ ê·¸ë¦¬ê¸°
                    cv2.rectangle(reference_overlay, (x1, y1 - text_h - baseline - 10), 
                                  (x1 + text_w, y1), (0, 255, 0), -1)
                    
                    # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
                    cv2.putText(reference_overlay, label, (x1, y1 - baseline - 5), 
                                font, font_scale, (255, 255, 255), thickness)
            
            # ì˜¤ë²„ë ˆì´ëœ ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ ì €ì¥
            overlay_path = os.path.join(output_dir, f"reference_overlay_{class_name}.jpg")
            cv2.imwrite(overlay_path, reference_overlay)
            print(f"ğŸ“¸ VP ì˜¤ë²„ë ˆì´ ì €ì¥: {overlay_path}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Model & palette â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
    # VP ëª¨ë¸ ë³„ë„ ë¡œë“œ
    model_vp = YOLOE(args.checkpoint)
    model_vp.eval()
    model_vp.to(args.device)
    
    # max_det ì„¤ì • (ìˆì„ ê²½ìš°)
    if hasattr(args, 'max_det') and args.max_det is not None:
        model_vp.model.model[-1].max_det = args.max_det
        print(f"ğŸ“Š ëª¨ë¸ max_det ì„¤ì •: {args.max_det}")
    
    # ğŸ§  VP & TP Embedding ì¶”ì¶œ
    final_vpe = None
    
    if vp_classes:
        print(f"\nğŸ¯ VP Embedding ì¶”ì¶œ ì¤‘... ({len(vp_classes)}ê°œ í´ë˜ìŠ¤)")
        
        # VPìš© ì´ë¯¸ì§€ë“¤ì„ PILë¡œ ë³€í™˜
        vp_pil_images = []
        for img in vp_images:
            frame_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            pil_frame = Image.fromarray(frame_rgb)
            vp_pil_images.append(pil_frame)
        
        # VP Embedding ì¶”ì¶œ
        model_vp.predict(
            source=vp_pil_images, 
            prompts=vp_data, 
            predictor=YOLOEVPSegPredictor, 
            return_vpe=True,
            verbose=False
        )
        
        if hasattr(model_vp, 'predictor') and hasattr(model_vp.predictor, 'vpe'):
            vp_embedding = model_vp.predictor.vpe
            print(f"âœ… VP Embedding ì¶”ì¶œ ì™„ë£Œ: {vp_embedding.shape}")
            
            # ë°°ì¹˜ ì°¨ì›ì´ ìˆìœ¼ë©´ í‰ê· í™”
            if len(vp_embedding.shape) > 2:
                vp_embedding = vp_embedding.mean(dim=0, keepdim=True)
                
            final_vpe = vp_embedding
        else:
            print("âš ï¸ VP Embedding ì¶”ì¶œ ì‹¤íŒ¨")
    
    if tp_classes:
        print(f"\nğŸ“ TP Embedding ì¶”ì¶œ ì¤‘... ({len(tp_classes)}ê°œ í´ë˜ìŠ¤)")
        
        # TP Embedding ì¶”ì¶œ
        tp_embedding = model_vp.get_text_pe(tp_classes)
        print(f"âœ… TP Embedding ì¶”ì¶œ ì™„ë£Œ: {tp_embedding.shape}")
        
        # VPì™€ TP Embedding ê²°í•©
        if final_vpe is not None:
            # VPì™€ TPë¥¼ ê²°í•© (í´ë˜ìŠ¤ ìˆœì„œ ë§ì¶¤)
            combined_embeddings = []
            
            for class_name in args.names:
                if class_name in vp_classes:
                    # VPì—ì„œ í•´ë‹¹ í´ë˜ìŠ¤ì˜ embedding ê°€ì ¸ì˜¤ê¸°
                    vp_idx = vp_classes.index(class_name)
                    if len(final_vpe.shape) == 3:  # (batch, classes, features)
                        class_embedding = final_vpe[:, vp_idx:vp_idx+1, :]
                    else:  # (classes, features)
                        class_embedding = final_vpe[vp_idx:vp_idx+1, :]
                    combined_embeddings.append(class_embedding)
                elif class_name in tp_classes:
                    # TPì—ì„œ í•´ë‹¹ í´ë˜ìŠ¤ì˜ embedding ê°€ì ¸ì˜¤ê¸°
                    tp_idx = tp_classes.index(class_name)
                    if len(tp_embedding.shape) == 3:  # (batch, classes, features)
                        class_embedding = tp_embedding[:, tp_idx:tp_idx+1, :]
                    else:  # (classes, features)
                        class_embedding = tp_embedding[tp_idx:tp_idx+1, :]
                    combined_embeddings.append(class_embedding)
            
            if combined_embeddings:
                final_vpe = torch.cat(combined_embeddings, dim=-2)  # í´ë˜ìŠ¤ ì°¨ì›ìœ¼ë¡œ ê²°í•©
                print(f"ğŸ”— VP+TP Embedding ê²°í•© ì™„ë£Œ: {final_vpe.shape}")
        else:
            final_vpe = tp_embedding
            print(f"ğŸ“ TP Embeddingë§Œ ì‚¬ìš©: {final_vpe.shape}")
    
    if final_vpe is None:
        print("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ embeddingì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
        args.cross_vp = False
    else:
        # ëª¨ë¸ì— ìµœì¢… VPE ì„¤ì •
        model_vp.set_classes(args.names, final_vpe)
        print(f"ğŸ¯ ìµœì¢… VPE ì„¤ì • ì™„ë£Œ: {args.names}")
    
    model_vp.predictor = None

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê¸°ë³¸ ê°ì§€ ì˜ì—­ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
    detection_area_polygon = None
    if args.detection_area:
        detection_area_polygon = parse_detection_area(args.detection_area)
        if detection_area_polygon is None:
            print("âš ï¸ ê¸°ë³¸ ê°ì§€ ì˜ì—­ íŒŒì‹± ì‹¤íŒ¨, ê¸°ë³¸ ê°ì§€ ì˜ì—­ ê¸°ëŠ¥ ë¹„í™œì„±í™”")
    else:
        print("ğŸ¯ ê¸°ë³¸ ê°ì§€ ì˜ì—­ ë¯¸ì„¤ì •, ëª¨ë“  ê°ì²´ ê°ì§€")    

    # Inference Thread ì‹œì‘
    inference_thread = InferenceThread(
        frame_queue=frame_queue,
        result_queue=result_queue,
        model_vp=model_vp,
        args=args,
        detection_area_polygon=detection_area_polygon
    )
    inference_thread.start()
    # print(f"ğŸ§  Stage 2 ì‹œì‘: Inference Thread (PID: {inference_thread.ident})")

    person_class_id = args.names.index("fish") if "fish" in args.names else 0
    palette = sv.ColorPalette.DEFAULT
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Tracker â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
    tracker = BoostTrack(
        video_name=args.source,
        det_thresh=args.track_det_thresh,
        iou_threshold=args.track_iou_thresh
    )

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Counting line (pixel) â”€â”€â”€â”€â”€ #
    if args.line_start is not None and args.line_end is not None:
        # ì…ë ¥ í•´ìƒë„ ê¸°ì¤€ìœ¼ë¡œ ë¼ì¸ ì¢Œí‘œ ê³„ì‚° (ë‚´ë¶€ ë¡œì§ìš©)
        p1_input = (int(args.line_end[0]   * width),  int(args.line_end[1]   * height))
        p2_input = (int(args.line_start[0] * width),  int(args.line_start[1] * height))
        
        # ì¶œë ¥ í•´ìƒë„ ê¸°ì¤€ìœ¼ë¡œ ë¼ì¸ ì¢Œí‘œ ê³„ì‚° (ì‹œê°í™”ìš©)
        p1 = (int(args.line_end[0]   * output_width),  int(args.line_end[1]   * output_height))
        p2 = (int(args.line_start[0] * output_width),  int(args.line_start[1] * output_height))
        
        # ì„ ë¶„ ë²¡í„° ë° ê¸¸ì´Â² ê³„ì‚° (ì…ë ¥ í•´ìƒë„ ê¸°ì¤€, ë‚´ë¶€ ë¡œì§ìš©)
        seg_dx, seg_dy = p2_input[0] - p1_input[0], p2_input[1] - p1_input[1]
        seg_len2 = seg_dx * seg_dx + seg_dy * seg_dy or 1
    else:
        p1 = p2 = None
        p1_input = p2_input = None
        seg_dx = seg_dy = seg_len2 = 0

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Runtime state â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
    track_history = defaultdict(list)
    track_side   = {}
    track_color  = {}
    forward_cnt = backward_cnt = 0

    # íŠ¸ë˜í‚¹ ë¼ì¸ ê´€ë ¨ ë³€ìˆ˜
    max_track_history = 30  # ìµœëŒ€ íŠ¸ë˜í‚¹ íˆìŠ¤í† ë¦¬ ê¸¸ì´
    line_thickness = 2     # ë¼ì¸ ë‘ê»˜
    line_opacity = 0.5     # ë¼ì¸ íˆ¬ëª…ë„

    # --- í”„ë¡¬í”„íŠ¸ ë°˜ë³µ ë¡œì§ìš© ìƒíƒœ ë³€ìˆ˜ --- #
    prev_prompt = None
    prompt_frame = None
    last_vp_frame = None
    last_vp_results = None
    
    # VPE moving average ìƒíƒœ ë³€ìˆ˜
    vpe_avg = None
    vpe_alpha = 0.9  # moving average ê³„ìˆ˜ (0.9 = ì´ì „ ê°’ì˜ 90% + í˜„ì¬ ê°’ì˜ 10%)

    # Heat-map ëˆ„ì  ë²„í¼
    heatmap = np.zeros((height, width), dtype=np.float32)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ROI Access Detection ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
    roi_manager = None
    if args.roi_zones:
        # ROI zones íŒŒì‹±
        roi_polygons = parse_roi_zones(args.roi_zones)
        if roi_polygons:
            # ROI names íŒŒì‹±
            roi_names = parse_roi_names(args.roi_names, len(roi_polygons))
            
            # ROI Access Manager ì´ˆê¸°í™”
            roi_manager = ROIAccessManager(
                roi_polygons=roi_polygons,
                roi_names=roi_names,
                detection_method=args.roi_detection_method,
                dwell_time=args.roi_dwell_time,
                bbox_threshold=args.roi_bbox_threshold,
                mask_threshold=args.roi_mask_threshold,
                fps=fps,
                exit_grace_time=args.roi_exit_grace_time
            )
        else:
            print("âš ï¸ ROI zones íŒŒì‹± ì‹¤íŒ¨, ROI ê¸°ëŠ¥ ë¹„í™œì„±í™”")
    else:
        print("ğŸ“ ROI zones ë¯¸ì„¤ì •, ROI ê¸°ëŠ¥ ë¹„í™œì„±í™”")

    # ë¼ì¸ ê¹œë°•ì„ ìƒíƒœ
    line_flash = False

    # 1ì´ˆë§ˆë‹¤ ê°±ì‹ ë˜ëŠ” ê°’ë“¤
    last_update_time = 0
    current_occupancy = 0
    current_congestion = 0
    frame_count = 0

    # ì¤‘ê°„ ì €ì¥ ê´€ë ¨ ë³€ìˆ˜
    last_save_frame = 0
    log_buffer = []  # ë¡œê·¸ ë²„í¼

    # ë¹„ë””ì˜¤ ì¶œë ¥ ì„¤ì • (ì¶œë ¥ í•´ìƒë„ ì‚¬ìš©)
    out = cv2.VideoWriter(output_video,
                        cv2.VideoWriter_fourcc(*'mp4v'),
                        fps, (output_width, output_height))

    # Pipeline í†µê³„
    pipeline_stats = {
        'processed_batches': 0,
        'processed_frames': 0,
        'start_time': time.time(),
        'empty_queue_waits': 0
    }

    print(f"\nğŸ¬ Process Results ì‹œì‘\n")
    
    pbar = tqdm(total=total_frames, desc="ğŸ”¥ Pipeline Processing")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸš€ MAIN THREAD RESULT PROCESSING LOOP ğŸš€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
    try:
        batch_idx = 0
        while True:
            try:
                # Result Queueì—ì„œ ì²˜ë¦¬ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° (íƒ€ì„ì•„ì›ƒ 3ì´ˆ)
                result_data = result_queue.get(timeout=3.0)
                
                # ì¢…ë£Œ ì‹ í˜¸ í™•ì¸
                if result_data is None:
                    print("ğŸ Main Thread: Inference Thread ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹ ")
                    break
                
                # ê²°ê³¼ ë°ì´í„° ì–¸íŒ¨í‚¹
                batch_detected_objects = result_data['batch_detected_objects']
                batch_indices = result_data['batch_indices']
                batch_original_frames = result_data['batch_original_frames']
                loaded_count = result_data['loaded_count']
                inference_batch_idx = result_data['batch_idx']
                vpe_updated = result_data['vpe_updated']
                prev_vpe_status = result_data['prev_vpe_status']
                
                # print(f"ğŸ“Š Main Thread: Batch {batch_idx + 1} ì²˜ë¦¬ ì‹œì‘ ({loaded_count} í”„ë ˆì„)")
                
                if not batch_detected_objects:
                    print("âš ï¸ ë¹ˆ ê²°ê³¼ ìˆ˜ì‹ , ê±´ë„ˆë›°ê¸°")
                    batch_idx += 1
                    continue
                
                # â”€â”€â”€â”€â”€â”€â”€â”€ 3. Batch ê²°ê³¼ ì²˜ë¦¬ (CPU ì‘ì—…) â”€â”€â”€â”€â”€â”€â”€â”€ #
                updated_state = process_batch_results(
                    batch_detected_objects, batch_indices, batch_original_frames,
                    tracker, args, fps, palette, person_class_id,
                    # ìƒíƒœ ë³€ìˆ˜ë“¤
                    track_history, track_side, track_color, 
                    forward_cnt, backward_cnt, current_occupancy, current_congestion,
                    last_update_time, heatmap, last_save_frame, log_buffer,
                    # I/O ê´€ë ¨
                    output_dir, out, log_file,
                    # ë¼ì¸ í¬ë¡œì‹± ê´€ë ¨
                    p1, p2, p1_input, p2_input, seg_dx, seg_dy, seg_len2,
                    width, height, output_width, output_height, scale_x, scale_y,
                    # Progress bar & Queue monitoring
                    pbar, frame_queue, result_queue, pipeline_stats,
                    # ROI Access Detection
                    roi_manager,
                    # Basic Detection Area
                    detection_area_polygon
                )
                
                # ìƒíƒœ ë³€ìˆ˜ ì—…ë°ì´íŠ¸
                forward_cnt = updated_state['forward_cnt']
                backward_cnt = updated_state['backward_cnt']
                current_occupancy = updated_state['current_occupancy'] 
                current_congestion = updated_state['current_congestion']
                last_update_time = updated_state['last_update_time']
                last_save_frame = updated_state['last_save_frame']
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                pipeline_stats['processed_batches'] += 1
                pipeline_stats['processed_frames'] += loaded_count
                
                # Progress bar postfix ì—…ë°ì´íŠ¸ (ì‹¤ì œ updateëŠ” process_batch_results ë‚´ë¶€ì—ì„œ í”„ë ˆì„ ë‹¨ìœ„ë¡œ)
                elapsed_time = time.time() - pipeline_stats['start_time']
                avg_fps = pipeline_stats['processed_frames'] / elapsed_time if elapsed_time > 0 else 0
                
                # ë°°ì¹˜ ì™„ë£Œ í›„ì—ëŠ” ë³„ë„ ì—…ë°ì´íŠ¸ ë¶ˆí•„ìš” (process_batch_resultsì—ì„œ í”„ë ˆì„ë³„ë¡œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ë¨)
                
                # print(f"âœ… Main Thread: Batch {batch_idx + 1} ì™„ë£Œ ({loaded_count} í”„ë ˆì„, VPE: {'Updated' if vpe_updated else 'Kept'})")
                batch_idx += 1
                
            except queue.Empty:
                pipeline_stats['empty_queue_waits'] += 1
                # print(f"â³ Result Queue ë¹„ì–´ìˆìŒ, ëŒ€ê¸° ì¤‘... ({pipeline_stats['empty_queue_waits']}íšŒ)")
                
                # Inference Threadê°€ ì•„ì§ ì‚´ì•„ìˆëŠ”ì§€ í™•ì¸
                if not inference_thread.is_alive():
                    print("ğŸ’€ Inference Thread ì¢…ë£Œë¨, Main Thread ì¢…ë£Œ")
                    break
                    
                continue
            
            except Exception as e:
                print(f"ğŸ’¥ Main Thread ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                import traceback
                traceback.print_exc()
                break
    
    finally:
        # â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ§¹ 3-Stage Pipeline ì •ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€ #
        print(f"\nğŸ§¹ 3-Stage Pipeline ì •ë¦¬ ì¤‘...")
        
        # Inference Thread ì¢…ë£Œ
        if inference_thread.is_alive():
            print("ğŸ›‘ Inference Thread ì¢…ë£Œ ìš”ì²­...")
            inference_thread.stop()
            inference_thread.join(timeout=5.0)
            if inference_thread.is_alive():
                print("âš ï¸ Inference Thread ê°•ì œ ì¢…ë£Œ íƒ€ì„ì•„ì›ƒ")
            else:
                print("âœ… Inference Thread ì •ìƒ ì¢…ë£Œ")
        
        # Frame Loading Thread ì¢…ë£Œ
        if frame_loader.is_alive():
            print("ğŸ›‘ Frame Loading Thread ì¢…ë£Œ ìš”ì²­...")
            frame_loader.stop()
            frame_loader.join(timeout=5.0)
            if frame_loader.is_alive():
                print("âš ï¸ Frame Loading Thread ê°•ì œ ì¢…ë£Œ íƒ€ì„ì•„ì›ƒ")
            else:
                print("âœ… Frame Loading Thread ì •ìƒ ì¢…ë£Œ")
        
        # Queue ì •ë¦¬
        print("ğŸ—‘ï¸ Queue ì •ë¦¬ ì¤‘...")
        queue_cleanup_count = 0
        
        # Frame Queue ì •ë¦¬
        while not frame_queue.empty():
            try:
                frame_queue.get_nowait()
                queue_cleanup_count += 1
            except queue.Empty:
                break
        
        # Result Queue ì •ë¦¬
        while not result_queue.empty():
            try:
                result_queue.get_nowait()
                queue_cleanup_count += 1
            except queue.Empty:
                break
        
        if queue_cleanup_count > 0:
            print(f"ğŸ—‘ï¸ Queueì—ì„œ {queue_cleanup_count}ê°œ ë¯¸ì²˜ë¦¬ ë°ì´í„° ì •ë¦¬ë¨")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ‰ Pipeline ì²˜ë¦¬ ì™„ë£Œ & ìµœì¢… í†µê³„ ğŸ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
    total_elapsed_time = time.time() - pipeline_stats['start_time']
    final_avg_fps = pipeline_stats['processed_frames'] / total_elapsed_time if total_elapsed_time > 0 else 0
    
    print(f"\nğŸ‰ Pipeline ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"ğŸ“Š ìµœì¢… í†µê³„:")
    print(f"   - ì´ ì²˜ë¦¬ëœ batch: {pipeline_stats['processed_batches']}/{total_batches}")
    print(f"   - ì´ ì²˜ë¦¬ëœ í”„ë ˆì„: {pipeline_stats['processed_frames']}/{total_frames}")
    print(f"   - ì´ ì²˜ë¦¬ ì‹œê°„: {total_elapsed_time:.1f}ì´ˆ")
    print(f"   - í‰ê·  FPS: {final_avg_fps:.1f}")
    print(f"   - Queue ë¹ˆ ëŒ€ê¸° íšŸìˆ˜: {pipeline_stats['empty_queue_waits']}")
    # print(f"   - VPE ìƒíƒœ: {'í™œì„±í™”' if prev_vpe is not None else 'ë¹„í™œì„±í™”'}")
    print(f"   - Batch í¬ê¸°: {batch_size}")
    print(f"   - Queue í¬ê¸°: {max_queue_size}")
    print(f"   - Frame Loading ìŠ¤ë ˆë“œ ìˆ˜: {args.frame_loading_threads}")
    
    print(f"ğŸ“ˆ ë¶„ì„ ê²°ê³¼:")
    print(f"   - ìµœì¢… occupancy: {current_occupancy}")
    print(f"   - ìµœì¢… congestion: {current_congestion}%")
    print(f"   - ë¼ì¸ í¬ë¡œì‹±: forward {forward_cnt}, backward {backward_cnt}")
    
    # ì „ì—­ í†µê³„ ê°ì²´ë¥¼ ì‚¬ìš©í•´ ìµœì¢… í†µê³„ ì¶œë ¥
    global confidence_stats
    confidence_stats.print_stats(args)
    
    # ROI ìµœì¢… í†µê³„ ì¶œë ¥ ë° ì €ì¥
    if roi_manager is not None:
        roi_manager.print_final_statistics()
        
        # ROI í†µê³„ JSON íŒŒì¼ë¡œ ì €ì¥
        roi_stats_path = os.path.join(output_dir, "roi_statistics.json")
        roi_manager.save_statistics(roi_stats_path)
    
    # if args.cross_vp and prev_vpe is not None:
    #     print(f"ğŸ§  VPE ì •ë³´:")
    #     print(f"   - VPE shape: {prev_vpe.shape}")
    #     print(f"   - VPE dtype: {prev_vpe.dtype}")
    #     print(f"   - Cross-VP ëª¨ë“œ: í™œì„±í™”")
    
# â”€â”€â”€â”€â”€â”€â”€â”€ ìŠ¤ë ˆë“œë³„ ìƒì„¸ í†µê³„ â”€â”€â”€â”€â”€â”€â”€â”€ #
    
    # Frame Loading Thread í†µê³„ ì¶œë ¥
    if hasattr(frame_loader, 'stats'):
        loader_stats = frame_loader.stats
        print(f"ğŸ“¦ Stage 1 - Frame Loading Thread í†µê³„:")
        print(f"   - ë¡œë“œëœ ë°°ì¹˜ ìˆ˜: {loader_stats['total_batches_loaded']}")
        print(f"   - ë¡œë“œëœ í”„ë ˆì„ ìˆ˜: {loader_stats['total_frames_loaded']}")
        print(f"   - ì‹¤íŒ¨í•œ í”„ë ˆì„ ìˆ˜: {loader_stats['failed_frames']}")
        
        # íš¨ìœ¨ì„± ê³„ì‚°
        if loader_stats['total_frames_loaded'] > 0:
            success_rate = (loader_stats['total_frames_loaded'] / 
                          (loader_stats['total_frames_loaded'] + loader_stats['failed_frames'])) * 100
            print(f"   - í”„ë ˆì„ ë¡œë”© ì„±ê³µë¥ : {success_rate:.1f}%")
    
    # Inference Thread í†µê³„ ì¶œë ¥
    if hasattr(inference_thread, 'stats'):
        inference_stats = inference_thread.stats
        print(f"ğŸ§  Stage 2 - Inference Thread í†µê³„:")
        print(f"   - ì²˜ë¦¬ëœ ë°°ì¹˜ ìˆ˜: {inference_stats['total_batches_processed']}")
        print(f"   - ì²˜ë¦¬ëœ í”„ë ˆì„ ìˆ˜: {inference_stats['total_frames_processed']}")
        print(f"   - VPE ì—…ë°ì´íŠ¸ íšŸìˆ˜: {inference_stats['vpe_updates']}")
        print(f"   - ì‹¤íŒ¨í•œ ë°°ì¹˜ ìˆ˜: {inference_stats['failed_batches']}")
        print(f"   - ê¸°ë³¸ ê°ì§€ ì˜ì—­ í•„í„°ë§ëœ ê°ì²´ ìˆ˜: {inference_stats['filtered_objects']}")
        
        # GPU íš¨ìœ¨ì„± ê³„ì‚°
        if inference_stats['total_batches_processed'] > 0:
            gpu_success_rate = ((inference_stats['total_batches_processed'] - inference_stats['failed_batches']) / 
                              inference_stats['total_batches_processed']) * 100
            vpe_update_rate = (inference_stats['vpe_updates'] / inference_stats['total_batches_processed']) * 100
            print(f"   - GPU ì¶”ë¡  ì„±ê³µë¥ : {gpu_success_rate:.1f}%")
            print(f"   - VPE ì—…ë°ì´íŠ¸ ë¹„ìœ¨: {vpe_update_rate:.1f}%")
    
    print(f"ğŸ“Š Stage 3 - Main Thread í†µê³„:")
    print(f"   - ì²˜ë¦¬ ì™„ë£Œëœ ë°°ì¹˜ ìˆ˜: {pipeline_stats['processed_batches']}")
    print(f"   - ì²˜ë¦¬ ì™„ë£Œëœ í”„ë ˆì„ ìˆ˜: {pipeline_stats['processed_frames']}")
    print(f"   - Queue ëŒ€ê¸° íšŸìˆ˜: {pipeline_stats['empty_queue_waits']}")
    
    # ì „ì²´ Pipeline íš¨ìœ¨ì„±
    if pipeline_stats['processed_frames'] > 0 and hasattr(loader_stats, 'total_frames_loaded'):
        pipeline_efficiency = (pipeline_stats['processed_frames'] / loader_stats['total_frames_loaded']) * 100
        print(f"   - Pipeline ì „ì²´ íš¨ìœ¨ì„±: {pipeline_efficiency:.1f}%")

    pbar.close()
    cap.release()
    if log_file is not None:
        if log_buffer:
            log_file.writelines(log_buffer)
        log_file.close()
    out.release()
    
    print(f"\nâœ” Pipeline ì²˜ë¦¬ ì™„ë£Œ! ì €ì¥ ìœ„ì¹˜: {output_dir}")


if __name__ == "__main__":
    main() 
